{"pages":[{"title":"About Me","text":"​ 程序员小黄，会吃福建人的广东人，面临90后中年危机，爱的人都叫夏洛特。 Roles 华南理工大学SE本科在读 M$ Club技术部指定背锅位 神(hua)出(shui)鬼(mo)没(yu)校园足球边裁 每次签到都慢过107的宿舍长 Projects赶过死线 云计算大作业 建模课大作业 数据库实训 西加加实训 搞过副业 卡片式日记应用开发 俱乐部门户网站开发 BCD实验室软件开发 抱过大腿 BBT SRP ACM GAC 互联网+ 黑客马拉松 微软空间站 看过风景 拼客学院Linux运维训练营 微软亚研2019技术夏令营 Focus 迷恋云计算，操着开发的心选的大数据（非ML狂热粉丝，水平止于调包 逃 FullStack爱好者（实际上是全菜工程师，手持跨平台开发、轻量级应用潜力股，用谷歌全家桶武装大脑 励志成为优秀的软件工程狮+架构狮，respect计算机科学家，认识超棒的设计狮+产品经理 Hobbies 努力为祖国健康打码五十年 诺基亚信仰用户，电子产品云收藏者 左派青年，涉猎文史哲 平权，能出力的出力，能发声的发声 书、歌、剧，赏画有待提高 曾经是一名不合格的剪刀手 热爱小语种，推广文言文 只有篆刻的时候字是允许丑的 FM拜仁Chef Coach，没事踢波 精神健身达人 Links Github Stack Overflow V2EX Zhihu Jianshu Gitee SegmentFault Todos 更新链接 丰富图片 详细介绍","link":"/about/index.html"}],"posts":[{"title":"\\#Machine Learning\\# Artificial Neural Network(1) Single-layer Perception(SLP)","text":"本文主要讨论单层感知机的概念和应用，包括以下六个部分： 单层感知机的结构 单层感知机的训练 单层感知机的应用 单层感知机的算法 本文关键术语 本文参考链接 结构一般结构单神经元感知机多神经元感知机训练学习规则概念训练最终任务具体学习规则 蒙特卡罗初始化 对w： ✖ 直接令权值矩阵w等于第一个输入 ✔ 将p加/减到w上面使得w更加偏向于p 对b： b_new = b_old + e 通过则读取下一个p，不通过则进行再适应，直至无输入后训练完成 ⭐ 应用❗ 算法自适应线性神经元网络 ADALINE Network 和传统感知机唯一不同的是它使用的是一个线性传输函数 最小均方算法 LMS 正确行为样本集合 均方误差表达式 相关矩阵表达式 最小均方算法流程 关键术语假设空间 感知机使用的传输函数为对称硬极限函数 对于单个神经元的单层感知机，输出只为1或-1，所以感知机是一种线性分类模型$$a = hardlims(n) =\\begin{cases}1,\\quad n\\geq 0\\\\-1,\\quad n&lt;0\\end{cases}$$ 感知机的假设空间是定义在特征空间中的所有线性分类模型或者线性分类器，即函数集合$${f | f(x) = w · x + b}$$ 判定边界 判定边界由那些使得净输入n为零的输入向量确定 右上阴影区任意输入向量和权值向量的内积 &gt; -b，左下阴影区任意输入向量和权值向量的内积 &lt; -b 右上阴影区任意输入向量和权值向量的输出a = 1，左下阴影区任意输入向量和权值向量的输出a = -1 权值向量总是指向神经元输出为1的区域 参考链接 神经网络（二）：感知机","link":"/2019/07/13/Artificial Neural Network(1) Single-layer Perception(SLP)/"},{"title":"\\#Machine Learning\\# Artificial Neural Network(0) Introduction","text":"本文主要讨论ANN的重要概念和核心问题，包括以下四个部分： ANN的基本结构 ANN的网络结构 ANN的核心问题 本文参考链接 基本结构单输入神经元多输入神经元网络结构单层神经元多层神经元核心问题 一个网络需要多少层？ 一个层需要多少神经元？ 一个神经元的权重、偏置和传输函数该如何选择？ 参考链接 神经网络（一）：概念","link":"/2019/07/13/Artificial Neural Network(0) Introduction/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(0) Introduction","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies Once you complete this course, you will have a good understanding of the terminology, tools, and technologies associated with today’s top cloud platforms, which can help pave the way to a lucrative career in technology. IntroductionConcept*”Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g. networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction”.* Terms nested virtualization overcommitting Features Speed and AgilityThe required resources are just one click away, which saves time and provides agility. We can also easily scale up or down, depending on our need. CostIt reduces the up-front cost to set up the infrastructure, and allows us to focus on applications and business. Cloud providers have features to estimate the cost, which helps us plan better. Easy Access to ResourcesAs users, we can access our infrastructure from any place and device, as long as we can connect to the provider. MaintenanceAll the maintenance work for the resources is done by the provider. As end users, we do not have to worry about this aspect. Multi-tenancyMultiple users can use the same pool of resources. ReliabilityResources can be hosted in different data center locations, to provide increased reliability. Category Infrastructure as a Service (IaaS) Platform as a Service (PaaS) Software as a Service (SaaS) Model Private CloudIt is designated and operated solely for one organization. It can be hosted internally or externally and managed by internal teams or a third party. We can build a private cloud using a software stack like OpenStack. Public CloudIt is open to the public and anybody can use it after swiping the credit card. Amazon Web Services and Google Compute Engine are examples of public clouds. Hybrid CloudPublic and private clouds are bound together to offer the hybrid cloud. Among other things, a hybrid cloud can be used to: Store sensitive information on a private cloud, while offering public services based on that information from a public cloud. Meet the temporary resources needed from the public cloud. These temporary resources cannot be met from a private cloud.","link":"/2019/07/11/Introduction to Cloud Infrastructure Technologies(0) Introduction/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(1) Virtualization","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies By the end of this chapter, you should be able to: Describe the different types of virtualization. Explain how hypervisors can be used to create virtual machines. Create and configure virtual machines automatically, using KVM, VirtualBox and Vagrant. VirtualizationConcept*”In computing, virtualization refers to the act of creating a virtual (rather than actual) version of something, including virtual computer hardware platforms, operating systems, storage devices, and computer resources”.* KVM VirtualBox VirtualBox is distributed under the GNU General Public License (GPL) version 2. VagrantConcept*”Configuring and sharing one VM is easy, but, when we have to deal with multiple VMs for the same project, doing everything manually can be tiresome. Vagrant by HashiCorp helps us automate the setup of one or more VMs by providing an end-to-end lifecycle using the vagrant command line. Vagrant is a cross-platform tool. It can be installed on Linux, Mac OSX, and Windows. We have to use different providers, depending on the OS. It has recently added support for Docker, which can help us manage Docker containers.“* Features Boxes We need to provide an image in the Vagrantfile, which we can use to instantiate machines. In the example above, we have used centos/7 as the base image. If the image is not available locally, then it can be downloaded from a central repository like Atlas, which is the image repository provided by HashiCorp. We can version these images and use them depending on our need, by updating the Vagrantfile accordingly. Vagrant Providers Providers are the underlying engine/hypervisor used to provision a machine. By default, Vagrant supports VirtualBox, Hyper-V and Docker. We also have custom providers, like KVM, AWS, etc. VirtualBox is the default provider. Synced Folders With the Synced Folder feature, we can sync a directory on the host system with a VM, which helps the user manage shared files/directories easily. For example, in the above example, if we un-comment the line below from Vagrantfile, then the ../data folder from the current working directory of the host system would be shared with the /vagrant_data file on the VM. 1config.vm.synced_folder &quot;../data&quot;, &quot;vagrant_data&quot; ProvisioningProvisioners allow us to automatically install software, make configuration changes, etc. after the machine is booted. It is a part of the vagrant up process. There are many types of provisioners available, such as File, Shell, Ansible, Puppet, Chef, Docker, etc. In the example below, we used Shell as the provisioner to install the vim package. 123config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL yum install vim -ySHELL PluginsWe can use plugins to extend the functionality of Vagrant. VagrantFile VagrantCmd vagrant up: start VM vagrant halt: stop VM vagrant destory: delete VM vagrant status: check status vagrant user: login in as user","link":"/2019/07/11/Introduction to Cloud Infrastructure Technologies(1) Virtualization/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(2) Infrastructure as a Service (IaaS)","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies By the end of this chapter, you should be able to: Explain the concept of Infrastructure as a Service (IaaS). Distinguish between different IaaS providers. Provision a virtual machine on top of different IaaS providers. Infrastructure as a Service (IaaS)Concept“Infrastructure as a Service (IaaS) is a form of cloud computing which provides on-demand physical and virtual computing resources, storage, network, firewall, load balancers, etc. To provide virtual computing resources, IaaS uses some form of hypervisor, like Xen, KVM, VMware ESX/ESXi, Hyper-V, etc.ther than VMs, some IaaS providers offer bare metal machines for provisioning”. Amazon EC2Concept*”Amazon Web Services (AWS) is one of the leaders in providing different cloud services. With Amazon Elastic Compute, Amazon provides the IaaS infrastructure, on which most of the other services are built. We can manage compute resources from the Amazon EC2 web interface and can scale up or down, depending on the need. AWS also offers a command line to manage the instances from the command line. Amazon EC2 uses XEN and KVM hypervisors to provision compute resources”.* Features Amazon EC2 offers compute instances for different resources, which we can choose from depending on our need. Amazon EC2 provides some preconfigured images, called Amazon Machine Images (AMIs). These images can be used to quickly start instances. We can also create our own custom AMIs to boot our instances. One important aspect to note is that Amazon supports configuring security and network access to our instances. With Amazon Elastic Block Store (EBS) we can attach/detach persistent storage to our instances. EC2 supports the provisioning of dedicated hosts, which means we can get an entire physical machine for our use. Create an Elastic IP for remapping the Static IP address automatically. Provision a Virtual Private Cloud for isolation. Amazon Virtual Private Cloud provides secure and robust networking for Amazon EC2 instances. Use CloudWatch for monitoring resources and applications. Use Auto Scaling to dynamically resize your resources, etc. Azure Virtual MachineConcept‘“Azure is Microsoft’s cloud offering, which has products in different domains, such as compute, web and mobile, data and storage, Internet of Things, and many others. Through Azure Virtual Machine, Microsoft provides compute provisioning and management: We can manage Virtual Machines from Azure’s web interface. Azure also provides a command line utility to manage resources and applications on the Azure cloud”. Features Azure lets you choose between different tiers, based on the usage and the operating systems or the predefined application virtual machines (SharePoint, Oracle, etc.). Using Resource Manager templates, we can define the template for the virtual machine deployment. Azure offers other features as well, like making seamless hybrid connections, faster I/O in certain types of tiers, backups, etc. Google Compute EngineConcept”Google Cloud Platform is Google’s Cloud offering, which has many products in different domains, like compute, storage, networking, big data, and others. Google Compute Engine provides the compute service. We can manage the instances through GUI, APIs or command line. Access to the individual VM’s console is also available“. Features GCE supports different machine types, which we can choose from depending on our need. GCE has other features as well, like Persistent Disk, Local SSD, Global Load Balancing, Compliance and Security, Automatic Discount, etc. DigitalOceanConcept*”DigitalOcean helps you create a simple cloud quickly, in as little as 55 seconds. All of the VMs are created on top of the KVM hypervisor and have SSD (Solid-State Drive) as the primary disk.”* Features Based on your need, DigitalOcean offers different plans. DigitalOcean provides other features, like Floating IPs, Shared Private Networking, Load Balancers, Team Accounts, etc. It offers a one-click installation of a multitude of application stacks like LAMP, LEMP, MEAN, and Docker. OpenStackConcept*”With OpenStack, we can offer a cloud computing platform for public and private clouds. Other than providing a IaaS solution, OpenStack has evolved over time to provide other services, like Database, Storage, etc”.* FeaturesDue to the modular nature of OpenStack, anyone can add additional components to get specific features or functionality. Some of the major OpenStack components are KeystoneProvides Identity, Token, Catalog, and Policy services to projects. NovaProvides on-demand compute resources. HorizonProvides the Dashboard, which is a web-based user interface to manage the OpenStack service. NeutronImplements the network as a service and provides network capabilities to different OpenStack components. GlanceProvides a service where users can upload and discover data assets, like images and metadata. SwiftProvides a highly available, distributed, eventually consistent object/blob store. CinderProvides block storage as a service. HeatProvides a service to orchestrate composite cloud applications, using a declarative template format through an OpenStack-native REST API. CeilometerIt is part of the Telemetry project and provides data collection services for billing and other purposes. Each of the OpenStack components is also modular by design. For example, with Nova we can select an underneath hypervisor depending on the requirement, which can be either libvirt (qemu/KVM), Hyper-V, VMware, XenServer, Xen via libvirt.","link":"/2019/07/12/Introduction to Cloud Infrastructure Technologies(2) Infrastructure as a Service (IaaS)/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(3) Platform as a Service (PaaS)","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies By the end of this chapter, you should be able to: Explain the concept of Platform as a Service (PaaS). Distinguish between different PaaS providers. Deploy an application on top of different PaaS providers: Cloud Foundry, OpenShift, Heroku. Platform as a Service (PaaS)Concept*”Platform as a Service (PaaS) is a class of cloud computing services which allows its users to develop, run, and manage applications without worrying about the underlying infrastructure. With PaaS, users can simply focus on building their applications, which is a great help to developers. We can either use PaaS services offered by different cloud computing providers like Amazon, Google, Azure, etc., or deploy it on-premise, using software like OpenShift Origin. PaaS can be deployed on top of IaaS, or, independently on VMs, bare metal, and containers”.* Cloud FoudryConcept*”Cloud Foundry CF) is an open source Platform as a Service (PaaS) that provides a choice of clouds, developer frameworks, and application services. It can be deployed on-premise or on IaaS, like AWS, vSphere, or OpenStack. There are many commercial CF cloud providers as well, like IBM Cloud Foundry, SAP Cloud Platform, Pivotal Cloud Foundry, etc”.* FeaturesAmong the characteristics employed by Cloud Foundry are the following: Application portability Application auto-scaling Centralized platform management Centralized logging Dynamic routing Application health management Role-based application deployment Horizontal and vertical scaling Security Support for different IaaS technologies. CF Application RuntimeConcept*”CF Application Runtime, previously known as Elastic Runtime, is used by developers to run applications written in any language or framework on the cloud of their choice”.* Features CF Application Runtime uses buildpacks, which provide the framework and runtime support for the applications. They are programming language-specific and have information about how to download dependencies and configure specific applications. Developers can build new buildpacks or customize the existing ones. In addition, by using the Open Service Broker API, we can connect our application to external services like databases or third-party SaaS providers. As presented in the graphic below, the CF Application Runtime platform can manage the entire workflow and lifecycle of the application, from routing to logging. CF Container RuntimeConcept*”CF Container Runtime gives Cloud Foundry the flexibility to deploy developer-built, pre-packaged applications using containers”.* Features BOSH is a cloud-agnostic open source tool for release engineering, deployment, and lifecycle management of complex distributed systems. Kubernetes is a container orchestrator which allows us to deploy containers. The CF Container Runtime platform does it by deploying containers on a Kubernetes cluster, which is managed by CF BOSH. With CF BOSH, you can achieve high availability, scaling, VM healing and upgrades for the Kubernetes cluster. OpenShiftConcept*”OpenShift is an open source PaaS solution provided by Red Hat. It is built on top of the container technology, which uses Kubernetes underneath. OpenShift can be deployed on top of a full-fledged Linux OS or on a Micro OS which is specifically designed to run containers and Kubernetes”.* Features With OpenShift, we can deploy containerized applications. With application images and QuickStart application templates, applications can be deployed with one click. As OpenShift uses Kubernetes, we get all the features offered by Kubernetes, like adding or removing nodes at runtime, persistent storage, auto-scaling, etc. OpenShift has a framework called Source to Image (S2I), which enables us to create container images from the source code repository to deploy applications easily. OpenShift integrates well with Continuous Deployment tools to deploy applications as part of the CI/CD pipeline. With CLI, GUI and IDE integration applications can be managed easily. It enables application portability, meaning that any application created on OpenShift can run on any platform that supports Docker. OpenShift integrated Docker registry, automatic edge load balancing, cluster logging, and integrated metrics. HerokuConcept“Heroku is a fully-managed container-based cloud platform, with integrated data services and a strong ecosystem. Heroku is used to deploy and run modern applications”. Applications should contain the source code, its dependency information and the list of named commands to be executed to deploy it, in a file called Procfile. For each supported language, it has a pre-built image which contains a compiler for that language. This pre-built image is referred to as a buildpack. Multiple buildpacks can be used together. We can also create a custom buildpack. While deploying, we need to send the application’s content to Heroku, either via Git, GitHub, Dropbox or via an API. Once the application is received by Heroku, a buildpack is selected based on the language of preference. To create the runtime which is ready for execution, we compile the application after fetching its dependency and configuration variables on the selected buildpack. This runtime is often referred to as a slug. We can also use third party add-ons to get access to value-added services like logging, caching, monitoring, etc. A combination of slug, configuration variables, and add-ons is referred to as a release, on which we can perform upgrade or rollback. Depending on the process-type declaration in the Procfile, a virtualized UNIX container is created to serve the process in an isolated environment, which can be scaled up or down, based on the requirements. Each virtualized UNIX container is referred to as a dyno. Each dyno gets its own ephemeral storage. Dyno Manager manages dynos across all applications running on Heroku. Features Individual components of an application can be scaled up or down using dynos. It is a very rich ecosystem, and it allows us to extend the functionality of an application with add-ons. Add-ons allow us to easily integrate our applications with other fully-managed cloud services like database, logging, email, etc. Applications can be easily integrated with Salesforce. It enables a development-friendly workflow. It provides the ability to do automated backups.","link":"/2019/07/12/Introduction to Cloud Infrastructure Technologies(3) Platform as a Service (PaaS)/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(7) Microservices","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies By the end of this chapter, you should be able to: Explain the concept of microservices. Discuss the benefits and challenges of using microservices. BackgroundOver the years, with different experiments, we evolved towards a new approach, in which a single application is deployed and managed via a small set of services. Each service runs its own process and communicates with other services via lightweight mechanisms like REST APIs. Each of these services is independently deployed and managed. Technologies like containers and unikernels are becoming default choices for creating such services. Concept“Microservices are small, independent processes that communicate with each other to form complex applications which utilize language-agnostic APIs. These services are small building blocks, highly decoupled and focused on doing a small task, facilitating a modular approach tosystem-building. The microservices architectural style is becoming the standard for building continuously deployed systems.” Approaches If you have a complex monolith application, then it is not advisable to rewrite the entire application from scratch. Instead, you should start carving out services from the monolith, which implement the desired functionalities for the code we take out from the monolith. Over time, all or most functionalities will be implemented in the microservices architecture. We can split the monoliths based on the business logic, front-end (presentation), and data access. In the microservices architecture it is recommended to have a local database for individual services. And, if the services need to access the database from other services, then we can implement an event-driven communication between these services. As mentioned earlier, we can split the monolith based on the modules of the monolith application and each time we do it, our monolith shrinks.","link":"/2019/07/17/Introduction to Cloud Infrastructure Technologies(7) Microservices/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(7) Unikernels","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies By the end of this chapter, you should be able to: Explain the concept of unikernels. Compare and contrast unikernels and containers. Concept“Unikernels are specialised, single-address-space machine images constructed by using library operating systems. With unikernels, we can also select the part of the kernel needed to run with the specific application. With unikernels, we can create a single address space executable, which has both application and kernel components. The image can be deployed on VMs or bare metal, based on the unikernel’s type.” Categories Specialized and purpose-built unikernelsThey utilize all the modern features of software and hardware, without worrying about the backward compatibility. They are not POSIX-compliant. Some examples of specialized and purpose-built unikernels are ING, HalVM, MirageOS, and Clive. Generalized ‘fat’ unikernels They run unmodified applications, which make them fat. Some examples of generalized ‘fat’ unikernels are BSD Rump kernels, OSv, Drawbridge, etc. ComponentsThe Unikernel goes one step further than other technologies, creating specialized virtual machine images with just: The application code The configuration files of the application The user-space libraries needed by the application The application runtime (like JVM) The system libraries of the unikernel, which allow back and forth communication with the hypervisor. Unikernel images would run directly on top of a hypervisor like Xen or on bare metal, based on the unikernel types. Unikernels and Constainers Both containers and unikernels can co-exist on the same host. They can be managed by the same Docker binary. Unikernels helped Docker to run the Docker Engine on top of Alpine Linux on Mac and Windows with their default hypervisors, which are xhyve Virtual Machine and Hyper-V VM respectively.","link":"/2019/07/17/Introduction to Cloud Infrastructure Technologies(7) Unikernels/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(5) Micro OSes for Containers","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies By the end of this chapter, you should be able to: Discuss the characteristics and functionality of Micro OSes, which are specially designed to run containers. Describe different Micro OSes designed to run containers: Project Atomic and Red Hat CoreOS, VMware Photon, and RancherOS. Deploy containers and containerized applications on Micro OSes. Concept“Once we remove the packages which are not required to boot the base OS and run container-related services, we are left with specialized OSes, which are referred to as Micro OSes for containers”. Atomic HostConcept*”Atomic Host is a lightweight operating system, assembled out of a specific RPM content. It allows us to run just containerized applications in a quick and reliable manner”.* Features Atomic Host can be based on Fedora, CentOS, or Red Hat Enterprise Linux (RHEL). Atomic Host is a sub-project of Project Atomic, which includes other sub-projects, such as Buildah, Cockpit and skopeo. Atomic Host comes out-of-the-box with Kubernetes installed. It also includes several Kubernetes utilities, such as etcd and flannel. ComponentsAtomic Host has a very minimal base OS, but it includes components like systemdand journald to help its users and administrators. It is built on top of the following: rpm-ostreeOne cannot manage individual packages on Atomic Host, as there is no rpm or other related commands. To get any required service, you would have to start a respective container. Atomic Host has two bootable, immutable, and versioned filesystems; one is used to boot the system and the other is used to fetch updates from upstream. rpm-ostree is the tool to manage these two versioned filesystems. systemdIt is used to manage system services for Atomic Host. DockerAtomic Host currently supports Docker as a container runtime. KubernetesWith Kubernetes, we can create a cluster of Atomic Hosts to run applications at scale. Atomic Host also comes with a command called atomic. This command provides a high-level, coherent entry point to the system, and fills in the gaps that are not filled by Linux container implementations, such as upgrading the system to the new rpm-ostree, running containers with pre-defined docker run options using labels, verifying an image, etc. Red Hat CoreOSConcept*”According to the “Bringing CoreOS Technology to Red Hat OpenShift to Deliver a Next-Generation Automated Kubernetes Platform” article posted on the CoreOS blog, Red Hat CoreOS will be based on Fedora and Red Hat Enterprise Linux sources, and is expected to ultimately supersede Atomic Host as Red Hat’s immutable, container-centric operating system”.* Others Atomic Host can be managed using tools such as Cockpit. Cockpit is a server manager that makes it easy to administer your GNU/Linux servers via a web browser. VMware PhotonConcept*”Photon OS™ is a technology preview of a minimal Linux container host provided by VMware. It is designed to have a small footprint and boot extremely quickly on VMware platforms”.* Features It supports Docker, rkt, and the Pivotal Garden container specifications. It also has a new, open source, yum-compatible package manager (tdnf). Photon OS™ is a security-hardened Linux. The kernel and other aspects of the Photon OS™ are built with an emphasis on security recommendations given by the Kernel Self-Protection Project (KSPP). It can be easily managed, patched, and updated. It also provides support for persistent volumes to store the data of cloud-native applications on VMware vSAN™ . RancherOSConcept*”RancherOS is a 20 MB Linux distribution that runs Docker containers. It has the least footprint of all the Micro OSes available nowadays. This is possible because it runs directly on top of the Linux kernel. RancherOS is a product provided by Rancher, which is an end-to-end platform used to deploy and run private container services”.* Features It automates OS configuration with cloud-init. It can be customized to add custom system Docker containers using the cloud-init file or Docker Compose. ComponentsRancherOS runs two instances of the Docker daemon. Just after booting, it starts the first instance of the Docker daemon with PID 1 to run system containers like dhcp, udev*,* etc. To run user-level containers, the System Docker daemon creates a service to start other Docker daemons. RancherOS also includes a CLI utility called ros, which can be used to control and configure the system.","link":"/2019/07/15/Introduction to Cloud Infrastructure Technologies(5) Containers Micro OSes for Container/"},{"title":"\\#Machine Learning\\# Artificial Neural Network(2) Multi-layer Perception(MLP)","text":"本文主要讨论多层感知机的概念和应用，包括以下七个部分： 神经网络结构 神经网络流程 神经网络原理 神经网络问题 阐述多层感知机例子 实现多层感知机源码 本文参考链接 结构输入层隐含层 只要隐含的节点足够多，就可以拟合任意函数。 隐含层越多，越容易拟合更复杂的函数。 隐含层的两个属性：每个隐含层的节点数、隐含层的层数。层数越多，每一层需要的节点数就会越少。 ![multi-layer perception](/images/multi-layer perception.png) 输出层流程我们的任务就是找到权值和偏置这些参数的值，使得输出的东西让我们满意，达到我们的要求。 前向过程 -&gt; 预测反向过程 -&gt; 训练原理通过合理地改变权值和偏置一点点的方式来让这个神经网络最后的结果向我们预期的结果进军，激活函数的选择对于神经网络的训练来说，也是很重要的。 ![delta change](/images/delta change.png) 问题过拟合 Q：模型拟合训练数据，泛化性较差，测试数据效果不好。 A：Dropout，在神经网络的层中，随机丢弃一些点，并且加强剩余的点，学习含有噪声的数据，增强模型的泛化性。 局部最优 Q：神经网络不是一个凸优化问题，存在大量的局部最优点，然而，神经网络的局部最优正好可以达到比较好的效果，全局最优反而容易拟合。 A：Adagrad，减少计算参数的复杂度，学习速率先快后慢，恰好达到局部最优。 梯度弥散 Q：神经网络的的激活函数，将信息上一层传递至下一层的变换，使模型学习到更加高阶的特征。Sigmoid函数，在反向传播中，梯度会急剧减少；Softplus是单侧抑制，即负值转换为正值，但没有稀疏激活性，即没有0状态。真正的神经元具有稀疏性，根据输入信号，选择响应或是屏蔽。 A：ReLU，y=max(0,x)，将负值抑制为0，即非激活状态，正值反馈。 例子以MNIST手写体为例子： 读取数据集（28×28的灰度图） 展开为一维（含有784个单元） 对于输入层而言，我们可以“设定”784个单元，分别接受每一个像素的值 对于输出层而言，我们可以只设定一个神经元，用来输出这个数字是几，我们也可以设定10个神经元，分别代表0到9，然后输出这个那个数字更加有可能 从上面看，设计输入层和输出层还是比较轻松的，但是设计隐藏层是比较难的，后面再讨论 训练神经网络 确定损失函数 随机梯度下降 测试神经网络 源码以MNIST手写体为例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data\"\"\"读取数据\"\"\"mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True) # 读取数据集sess = tf.InteractiveSession() # 创建交互会话\"\"\"创建模型\"\"\"in_units = 28 * 28 # 输入层有784个单元h1_units = 300 # 隐含层1有300个单元out_units = 10 # 输出层有10个单元# 初始化隐藏层W1# 使用truncated_normal加噪，防止正态分布的完全对称W1 = tf.Variable(tf.truncated_normal([in_units, h1_units], stddev=0.1))# 初始化隐藏层b1# 矩阵用大写字母，向量用小写字母b1 = tf.Variable(tf.zeros[h1_units])# 初始化输出层W2W2 = tf.Variable(tf.zeros([h1_units, out_units]))# 初始化输出层b2b2 = tf.Variable(tf.zeros([out_units]))# 回归函数：y = wx + b# 激活函数：ReLUx = tf.placeholder(tf.float32, [None, in_units]) # 输入层h1 = tf.nn.relu(tf.matmul(x, W1) + b1) # 隐藏层keep_prob = tf.placeholder(tf.float32) # dropout的保留比率h1_dropout = tf.nn.dropout(h1, keep_prob) # 隐藏层的dropouty = tf.nn.softmax(tf.matmul(h1, W2) + b2) # 输出层# 损失函数：标准的交叉熵y_ = tf.placeholder(tf.float32, [None, out_units]) # 待训标签cross_entroy = tf.reduce_mean(tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) # 交叉熵train_step = tf.train.AdagradDAOptimizer(0.3) # 训练步长# 初始化全部变量tf.global_variables_initializer().run()\"\"\"训练模型\"\"\"# 循环训练模型3000次，每次随机采样100个数据# Feed三类数据：数据x，标签y_，dropout的保留比率keep_probfor i in range(3000): batch_xs, batch_ys = mnist.train.next_batch(100) # 随机采样 train_step.run({x: batch_xs, y_: batch_ys, keep_prob: 0.75}) # 训练数据\"\"\"测试模型\"\"\"# argmax选择最大数的索引，全部数据求平均# keep_prob设置为1，不丢弃任何信息correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))# 计算并输出准确率结果print(accuracy.eval({x: mnist.test.image, y_: mnist.test.labels, keep_prob: 1.0})) 参考链接 深度学习笔记二：多层感知机（MLP）与神经网络结构 MNIST数据集下载 MNIST数据集介绍及读取 人工智能 - 多层感知机 MLP [3]","link":"/2019/07/13/Artificial Neural Network(2) Multi-layer Perception(MLP)/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(4) Containers","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies By the end of this chapter, you should be able to: Discuss about containers and their runtimes. Describe the basic Docker operations. Understand how Project Moby helps create container platforms like Docker. Concept*”Operating-System-level virtualization allows us to run multiple isolated user-space instances in parallel. These user-space instances have the application code, the required libraries, and the required runtime to run the application without any external dependencies. These user-space instances are referred to as containers“.* TermsImages In the container world, this box (containing our application and all its dependencies) is referred to as an image. An image contains the application, its dependencies and the user-space libraries. User-space libraries like glibc enable switching from the user-space to the kernel-space. An image does not contain any kernel-space components. Container A running instance of this box is referred to as a container. We can spin multiple containers from the same image. When a container is created from an image, it runs as a process on the host’s kernel. It is the host kernel’s job to isolate and provide resources to each container. Building BlocksNamespacesA namespace wraps a particular global system resource like network, process IDs in an abstraction, that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource. The following global resources are namespaced: pid - provides each namespace to have the same PIDs. Each container has its own PID 1. net - allows each namespace to have its network stack. Each container has its own IP address. mnt - allows each namespace to have its own view of the filesystem hierarchy. ipc - allows each namespace to have its own interprocess communication. uts - allows each namespace to have its own hostname and domainname. user - allows each namespace to have its own user and group ID number spaces. A rootuser inside a container is not the root user of the host on which the container is running. cgroupsControl groups are used to organize processes hierarchically and distribute system resources along the hierarchy in a controlled and configurable manner. The following cgroups are available for Linux: blkio cpu cpuacct cpuset devices freezer memory. Union filesystemThe Union filesystem allows files and directories of separate filesystems, known as layers, to be transparently overlaid on each other, to create a new virtual filesystem. An image used in Docker is made of multiple layers and, while starting a new container, we merge all those layers to create a read-only filesystem. On top of a read-only filesystem, a container gets a read-write layer, which is an ephemeral layer and it is local to the container. RuntimesrunCOver the past few years, we have seen a rapid growth in the interest and adoption for container technologies. Most of the cloud providers and IT vendors offer support for containers. To make sure there is no vendor locking and no inclination towards a particular company or project, IT companies came together and formed an open governance structure, called The Open Container Initiative, under the auspices of The Linux Foundation. The governance body came up with specifications to create standards on Operating System process and application containers. runC is the CLI tool for spawning and running containers according to these specifications. containerdcontainerd is an Open Container Initiative (OCI)-compliant container runtime with an emphasis on simplicity, robustness and portability. It runs as a daemon and manages the entire lifecycle of containers. It is available on Linux and Windows. Docker, which is a containerization platform, uses containerd as a container runtime to manage runC containers. rktrkt (pronounced “rock-it”) is an open source, Apache 2.0-licensed project from CoreOS. It implements the App Container specification. CRI-OCRI-O is an OCI-compatible runtime, which is an implementation of the Kubernetes Container Runtime Interface (CRI). It is a lightweight alternative to using Docker as the runtime for Kubernetes. Project MobyProblemFrom the user perspective, we usually get a seamless experience, irrespective of the underlying platform. However, behind the scenes, someone connects different components like containers runtime, networking, storage, etc. to ensure this high quality experience. Open source projects like containerd and libnetwork are part of the container platform and have their own release cycle, governing model, etc. So, how can we take those individual components and build a container platform like Docker? SolutionProject Moby is the answer. It is an open source project which provides a framework for assembling different container systems to build a container platform like Docker. Individual container systems provide features like image, container, secret management, etc. ApplicationMoby is particularly useful if you want to build your container-based system or just want to experiment with the latest container technologies. It is not recommended for application developers and newbies who are looking for an easy way to run containers. LinuxKit, which is a tool to build minimal Linux distributions to run containers, uses Moby. You can find a few examples at its GitHub repository. DockerConcept*”Docker, Inc. is a company which provides Docker Containerization Platform to run applications using containers. Docker has a client-server architecture, in which a Docker client connects to a server (Docker Host) and executes the commands”.* CommandsYou can find a list of basic Docker operations below: Check version: 1$ docker version About daemon: 1$ docker info List images: 1$ docker image ls Pulling an alpine image: 1$ docker image pull alpine: latest Delete an image: 1$ docker container rm &lt;image id/name&gt; Run a container from a locally-available image: 1$ docker container run -it alpine sh Run a container in the background (-d option) from an image: 1$ docker container run -d --name web nginx List only running containers: 1$ docker container ls List all containers: 1$ docker container ls -a Inject a process inside a running container: 1$ docker container exec -it &lt;container_id/name&gt; bash Stop a container: 1$ docker container stop &lt;container id/name&gt; Delete a container: 1$ docker container rm &lt;container id/name&gt; Containers vs VMs A virtual machine runs on top of a hypervisor, which emulates different hardware, like CPU, memory, etc., so that a guest OS can be installed on top of them. Different kinds of guest OSes can run on top of one hypervisor. Between an application running inside a guest OS and in the outside world, there are multiple layers: the guest OS, the hypervisor, and the host OS. On the other hand, containers run directly as a process on top of the Host OS. There is no indirection as we see in VMs, which help containers to get near-native performance. Also, as the containers have very little footprint, we can pack a higher number of containers than VMs on the same physical machine. As containers run on the host OS, we need to make sure containers are compatible with the host OS.","link":"/2019/07/14/Introduction to Cloud Infrastructure Technologies(4) Containers/"},{"title":"\\#Configuration\\# 从零到壹：GitHub Pages + Hexo = Blog","text":"利用GitHub Pages+Hexo打造一个个人博客，主要分为以下五个部分： 环境准备 Environment 文件配置 Configuration 个性化 Customization 博客写作 Writing 双备份 Backup 环境准备 Environment安装Git + Github 安装Git部署插件: 1$ npm install hexo-deployer-git --save 安装Node.js 安装Node.js: Download | Node.js 检查是否安装成功: 12$ node -v$ npm -v 安装Hexo 安装Hexo: 1$ npm install -g hexo-cli 检查是否安装成功: 1$ hexo -v 初始化: 1$ hexo init blog 文件配置 Configuration本地运行123$ hexo clean # 删除缓存$ hexo g # 生成Hexo页面$ hexo s # 本地部署Hexo页面 远程运行123$ hexo clean # 删除缓存$ hexo g # 生成Hexo页面$ hexo d # 远程部署Hexo页面 基本配置/_config.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: LotteWong # 个人博客显示名称subtitle: 在代码符号表象中避难。 # 个人博客副标题description: # 搜索引擎描述信息keywords: # 搜索引擎关键词author: LotteWong # 网站作者avatar: ./themes/icarus/source/images/favicon.ico # 网站头像language: en # 网站语言timezone: Asia/HongKong # 网站时区# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/plugins: # 设置个人博客插件theme: icarus # 设置个人博客主题# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git # 部署类型 repo: git@github.com:LotteWong/lottewong.github.io.git # 部署仓库 branch: master # 部署分支 个性化 Customization/themes/icarus/_config.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234# Version of the Icarus theme that is currently usedversion: 2.3.0# Path or URL to the website's iconfavicon: /images/favicon.ico# Path or URL to RSS atom.xmlrss: # Path or URL to the website's logo to be shown on the left of the navigation bar or footerlogo: /images/logo.png# Open Graph metadata# https://hexo.io/docs/helpers.html#open-graphopen_graph: # Facebook App ID # fb_app_id: # Facebook Admin ID # fb_admins: # Twitter ID # twitter_id: # Twitter site # twitter_site: # Google+ profile link # google_plus: # Navigation bar link settingsnavbar: # Navigation bar menu links menu: Home: / Archives: /archives Categories: /categories Tags: /tags About: /about # Navigation bar links to be shown on the right # links: # Download on GitHub: # icon: fab fa-github # url: 'https://github.com/LotteWong'# Footer section link settingsfooter: # Links to be shown on the right of the footer section links: Github: icon: fab fa-github url: 'https://github.com/LotteWong' RSS: icon: fas fa-rss url: 'https://www.zhihu.com/people/lai-xiu-ping'# Article display settingsarticle: # Code highlight theme # https://github.com/highlightjs/highlight.js/tree/master/src/styles highlight: atom-one-light # Whether to show article thumbnail images thumbnail: true # Whether to show estimate article reading time readtime: true# Search plugin settings# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Searchsearch: # Name of the search plugin type: insight# Comment plugin settings# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Commentcomment: # Name of the comment plugin type: # Donation entries# https://ppoffice.github.io/hexo-theme-icarus/categories/Donation/donate: - # Donation entry name type: alipay # Qrcode image URL qrcode: '/images/alipay.png' - # Donation entry name type: wechat # Qrcode image URL qrcode: '/images/wechat.png' - # Donation entry name type: paypal # Paypal business ID or email address business: 'SuperGsama@outlook.com' # Currency code currency_code: USD - # Donation entry name # type: patreon # URL to the Patreon page # url: ''# Share plugin settings# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Shareshare: # Share plugin name type: # Sidebar settings.# Please be noted that a sidebar is only visible when it has at least one widgetsidebar: # left sidebar settings left: # Whether the left sidebar is sticky when page scrolls # https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/make-a-sidebar-sticky-when-page-scrolls/ sticky: false # right sidebar settings right: # Whether the right sidebar is sticky when page scrolls # https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/make-a-sidebar-sticky-when-page-scrolls/ sticky: false# Sidebar widget settings# https://ppoffice.github.io/hexo-theme-icarus/categories/Widgets/widgets: - # Widget name type: profile # Where should the widget be placed, left or right position: left # Author name to be shown in the profile widget author: LotteWong # Title of the author to be shown in the profile widget author_title: SCUT, Undergraduate # Author's current location to be shown in the profile widget location: Guangzhou, China # Path or URL to the avatar to be shown in the profile widget avatar: # Email address for the Gravatar to be shown in the profile widget gravatar: # Whether to show avatar image rounded or square avatar_rounded: false # Path or URL for the follow button follow_link: 'https://www.jianshu.com/u/80ee6b6f3418' # Links to be shown on the bottom of the profile widget social_links: Project: icon: fab fa-creative-commons url: 'https://github.com/scutse-man-month-myth/InkYear' Organization: icon: fab fa-creative-commons-by url: 'https://github.com/scutse-man-month-myth' Developer: icon: fab fa-github url: 'https://github.com/LotteWong' #Facebook: #icon: fab fa-facebook #url: 'https://facebook.com' #Twitter: #icon: fab fa-twitter #url: 'https://twitter.com' #Dribbble: #icon: fab fa-dribbble #url: 'https://dribbble.com' - # Widget name type: toc # Where should the widget be placed, left or right position: left - # Widget name type: links # Where should the widget be placed, left or right position: left # Links to be shown in the links widget links: Dart: 'https://dart.dev/' Flutter: 'https://flutter.dev/' - # Widget name type: category # Where should the widget be placed, left or right position: left - # Widget name type: tagcloud # Where should the widget be placed, left or right position: left - # Widget name type: recent_posts # Where should the widget be placed, left or right position: right - # Widget name type: archive # Where should the widget be placed, left or right position: right - # Widget name type: tag # Where should the widget be placed, left or right position: right# Other plugin settingsplugins: # Enable page animations animejs: true # Enable the lightGallery and Justified Gallery plugins # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/gallery-plugin/ gallery: true # Enable the Outdated Browser plugin # http://outdatedbrowser.com/ outdated-browser: true # Enable the MathJax plugin # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/mathjax-plugin/ mathjax: true # Show the back to top button on mobile devices back-to-top: true # Google Analytics plugin settings # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Google-Analytics google-analytics: # Google Analytics tracking id tracking_id: # Baidu Analytics plugin settings # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Baidu-Analytics baidu-analytics: # Baidu Analytics tracking id tracking_id: # Hotjar user feedback plugin # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Hotjar hotjar: # Hotjar site id site_id: # Show a loading progress bar at top of the page progressbar: true # Show the copy button in the highlighted code area clipboard: true # BuSuanZi site/page view counter # https://busuanzi.ibruce.info busuanzi: false# CDN provider settings# https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/speed-up-your-site-with-custom-cdn/providers: # Name or URL of the JavaScript and/or stylesheet CDN provider cdn: jsdelivr # Name or URL of the webfont CDN provider fontcdn: google # Name or URL of the webfont Icon CDN provider iconcdn: fontawesome 博客写作 Writing 默认 1$ hexo new \"blog title\" 自定义 1234567891011title: {{ blog title }}categories: {{ blog category }}tags:- {{ blog tag }}thumbnail: {{ blog thumbnail }}{{ Abstract }}&lt;!-- more --&gt;{{ Content }} 双备份 Backup Hexo备份: 12# master branch$ hexo d Src备份: 12345# dev branch$ git checkout dev$ git add --all$ git commit -m \"new blog\"$ git push origin dev 待办事项 Todos 对应图标 更多插件 绑定域名 更新外链 参考链接 References GitHub+Hexo 搭建个人网站详细教程 Hexo icarus","link":"/2019/07/10/从零到壹：GitHub Pages + Hexo = Blog/"},{"title":"\\#Cloud Computing\\# Introduction to Cloud Infrastructure Technologies(6) Container Orchestration","text":"Welcome to LFS151x: Introduction to Cloud Infrastructure Technologies By the end of this chapter, you should be able to: Describe different container orchestration tools: Docker Swarm, Kubernetes, Mesos, Nomad, Amazon ECS. Describe different Kubernetes hosted services like AWS Elastic Kubernetes Service (EKS), Azure Kubernetes Services (AKS) and Google Kubernetes Engine (GKE). Deploy sample applications using various container orchestration tools: Docker Swarm, Kubernetes, Mesos, Nomad, Amazon ECS. Concept”Container orchestration is an umbrella term which encompasses container scheduling and cluster management. Container scheduling allows us to decide on which host a container or a group of containers should be deployed. With the cluster management orchestrator we can manage the existing nodes, add or delete nodes, etc.“ Docker SwarmConcept”Docker Swarm is a native container orchestration tool from Docker, Inc. It logically groups multiple Docker engines to create a virtual engine, on which we can deploy and scale applications.“ Features It is compatible with Docker tools and API, so that the existing workflow does not change much. It provides native support to Docker networking and volumes. It can scale up to large numbers of nodes. It supports failover and High Availability for the cluster manager. It uses a declarative approach to define the desired state of the various services of the application stack. For each service, you can declare the number of tasks you want to run. When you scale up or down, the Swarm manager automatically adapts by adding or removing tasks to maintain the desired state. The Docker Swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state and your expressed desired state. The communication between the nodes of Docker Swarm is enforced with Transport Layer Security (TLS), which makes it secure by default. It supports rolling updates, using which we can control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll back a task to a previous version of the service. Components Swarm Manager NodesThere can be one or more manager nodes. They accept commands on behalf of the cluster and make scheduling decisions. They also store the cluster state using the Internal Distributed State Store, which uses the Raft consensus algorithm. One or more nodes can be configured as managers, but they work in active/passive modes. Swarm Worker NodesThey run the Docker Engine and the sole purpose of the worker nodes is to run the container workload given by the manager node(s). Docker MachineConcept”Docker Machine helps us configure and manage one or more Docker engines running locally or on cloud environments. With Docker Machine we can start, inspect, stop, and restart a managed host, upgrade the Docker client and daemon, and configure a Docker client to talk to our host. We can also use Docker Machine to configure a Swarm cluster.“ CommandsDocker Machine has drivers for Amazon EC2, Google Cloud, Digital Ocean, Vagrant, etc., to set up Docker engines. You can also add already running instances of the Docker engine to the Docker Machine: Setting up the Docker engine using the VirtualBox driver: 1$ docker-machine create -d virtualbox dev1 Setting up the Docker engine using DigitalOcean: 1$ docker-machine create --driver digitalocean --digitalocean-access-token=&lt;TOKEN&gt; dev2 Docker ComposeConcept“Docker Compose allows us to define and run multi-container applications through a configuration file. In a configuration file, we can define services, images or Dockerfiles to use, network, etc. Docker Swarm uses Docker Stack to deploy the distributed applications. We can use Docker Compose to generate the stack file, which can be used to deploy applications on Docker Swarm.” DockerFile Docker DatacenterConcept“Docker has another project called Docker Datacenter, which is built on top of UCP and Docker Trusted Registry. Docker Datacenter is hosted completely behind the firewall. With Docker Datacenter we can build an enterprise-class CaaS platform on-premises, as it is built on top of Docker Swarm and integrates well with Docker tools, Docker Registry. It also has other features, such as LDAP/AD integration, monitoring, logging, network and storage plugins.” Docker Enterprise EditionConcept“Docker Enterprise Edition (EE) 2.0 is the Container-as-a-Service (CaaS) platform that manages the entire lifecycle of the applications on enterprise Linux or Windows operating systems and Cloud providers. It supports Docker Swarm and Kubernetes as container orchestrators.” Features It is a multi-Linux, multi-OS, multi-Cloud solution. It supports Docker Swarm and Kubernetes as container orchestrators. It provides centralized cluster management. It has a built-in authentication mechanism with role-based access control (RBAC). Components Docker EE EngineIt is a commercially supported Docker Engine for creating images and running Docker containers. Docker Trusted Registry (DTR) It is a production-grade image registry designed to store images, from Docker, Inc. Universal Control Plane (UCP)It manages the Kubernetes and Swarm orchestrators, deploys applications using the CLI and GUI, and provides High Availability. UCP also provides role-based access control to ensure that only authorized users can make changes and deploy applications to your cluster. KubernetesConcept“Kubernetes is an Apache 2.0-licensed open source project for automating deployment, operations, and scaling of containerized applications. It was started by Google, but many other companies like Docker, Red Hat, and VMware contributed to it. Kubernetes supports container runtimes like Docker, CRI-O, etc., to run containers.” Features It automatically places containers based on resource requirements and other constraints. It supports horizontal scaling through the CLI and GUI. It can auto-scale based on the CPU load as well. It supports rolling updates and rollbacks. It supports multiple volume plugins like the GCP/AWS disk, NFS, iSCSI, Ceph, Gluster, Cinder, Flocker, etc. to attach volumes to pods. It automatically self-heals by restarting failed pods, rescheduling pods from failed nodes, etc. It deploys and updates secrets for an application without rebuilding the image. It supports batch execution. It support High Availability cluster. It eliminates infrastructure lock-in by providing core capabilities for containers without imposing restrictions. We can deploy and update the application at scale. Components ClusterThe cluster is a group of systems (physical or virtual) and other infrastructure resources used by Kubernetes to run containerized applications. Master NodeThe master is a system that takes pod scheduling decisions and manages the replication and manager nodes. It has three main components: API Server, Scheduler, and Controller. There can be more than one master node. Worker NodeA system on which pods are scheduled and run. The node runs a daemon called kubelet to communicate with the master node. kube-proxy, which runs on all nodes, allows applications from the external world. Key-Value StoreThe Kubernetes cluster state is saved in a key-value store, like etcd. It can be either part of the same Kubernetes cluster or it can resides outside. PodThe pod is a co-located group of containers with shared volumes. It is the smallest deployment unit in Kubernetes. A pod can be created independently, but it is recommended to use the Replica Set, even if only a single pod is being deployed. Replica SetThe Replica Set manages the lifecycle of pods. It makes sure that the desired numbers of pods is running at any given point in time. DeploymentsDeployments allow us to provide declarative updates for pods and Replica Sets. We can define Deployments to create new resources, or replace existing ones with new ones. ServiceThe service groups sets of pods together and provides a way to refer to them from a single static IP address and the corresponding DNS name. LabelThe label is an arbitrary key-value pair which is attached to a resource like pod, Replica Set, etc. In the example above, we defined labels as app and tier. SelectorSelectors enable us to group resources based on labels. In the above example, the frontend service will select all pods which have the labels app==dockchat and tier==frontend. VolumeThe volume is an external filesystem or storage which is available to pods. They are built on top of Docker volumes. NamespaceThe namespace allows us to partition the cluster into sub-clusters. KubernetesFileSome typical use cases are presented below: Create a Deployment to bring up a Replica Set and pods. Check the status of a Deployment to see if it succeeds or not. Later, update that Deployment to recreate the pods (for example, to use a new image). Roll back to an earlier Deployment revision if the current Deployment isn’t stable. Pause and resume a Deployment. Below we provide a sample deployment: Kubernetes Hosted SolutionsConcept“Kubernetes can be deployed anywhere, be it on-premise or on-cloud. If we are deploying on-premise, then our Kubernetes administrators would have to perform all the Kubernetes management tasks like upgrading, back up, etc. With an on-cloud setup, we have different options. For instance, we can manage our own on-premise or opt for hosted Kubernetes services in which all the management tasks would be performed by the service providers.” There are many hosted solutions available for Kubernetes, including: Google Kubernetes EngineOffers managed Kubernetes clusters on Google Cloud Platform. Amazon Elastic Container Service for Kubernetes (Amazon EKS)Offers a managed Kubernetes service on AWS. Azure Kubernetes Service (AKS)Offers a managed Kubernetes clusters Microsoft Azure. Stackpoint.ioProvides Kubernetes infrastructure automation and management for multiple public clouds. OpenShift DedicatedOffers managed Kubernetes clusters powered by Red Hat. Google Kubernetes Engine (GKE)Concept“Google Kubernetes Engine is a fully-managed solution for running Kubernetes on Google Cloud. As we have learned earlier, Kubernetes is used for automating deployment, operations, and scaling of containerized applications. In GKE, Kubernetes can be integrated with all Google Cloud Platform’s services, like Stackdriver monitoring, diagnostics, and logging, identity and access management, etc.” Features It has all of Kubernetes’ features. It runs on a container-optimized OS built and managed by Google. It is a fully-managed service, so the users do not have to worry about managing and scaling the cluster. We can store images privately, using the private container registry. Logging can be enabled easily using Google Cloud Logging. It supports Hybrid Networking to reserve an IP address range for the container cluster. It enables a fast setup of managed clusters. It facilitates increased productivity for Dev and Ops teams. It is Highly Available in multiple zones and SLA promises 99.5% of availability. It has Google-grade managed infrastructure. It can be seamlessly integrated with all GCP services. It provides a feature called Auto Repair, which initiates a repair process for unhealthy nodes. Amazon Elastic Container Service for Kubernetes (EKS)Concept“Amazon Elastic Container Service for Kubernetes is a hosted Kubernetes service offered by AWS. With Amazon EKS, users don’t need to worry about the infrastructure management, deployment and maintenance of the Kubernetes control plane. EKS provides a scalable and highly-available control plane that runs across multiple AWS availability zones. It can automatically detect the unhealthy Kubernetes control plane nodes and replace them. EKS also supports cluster autoscaling, using which it can dynamically add worker nodes, based on the workload. It also integrates with Kubernetes RBAC (Role-Based Control Access) to support AWS IAM authentication.” Features No need to manage the Kubernetes Control Plane. Provides secure communication between the worker nodes and the control plane. Supports auto scaling in response to changes in load. Well integrated with various AWS services, like IAM and CloudTrail. Certified hosted Kubernetes platform. Azure Kubernetes Service (AKS)Concept“Azure Kubernetes Service is a hosted Kubernetes service offered by Microsoft Azure. AKS offers a fully-managed Kubernetes container orchestration service, which reduces the complexity and operational overhead of managing Kubernetes. AKS handles all of the cluster management tasks, health monitoring, upgrades, scaling, etc. AKS also supports cluster autoscaling using which it can dynamically add worker nodes, based on the workload. It supports Kubernetes RBAC (Role-Based Control Access) and can integrate with Azure Active Directory for identity and security management.” Features No need to manage the Kubernetes Control Plane. Supports GUI and CLI-based deployment. Integrates well with other Azure services. Certified hosted Kubernetes platform. Compliant with SOC and ISO/HIPAA/HITRUST. Apache MesosConcept“Apache Mesos was created with this idea in mind, so that we can optimally use the resources available, even if we are running disparate applications on a pool of nodes. It helps us treat a cluster of nodes as one big computer, which manages CPU, memory, and other resources across a cluster. Mesos provides functionality that crosses between Infrastructure as a Service (IaaS) and Platform as a Service (PaaS).” Features It can scale up to 10,000 nodes. It uses ZooKeeper for fault-tolerant replicated master and slaves. It provides support for Docker containers. It enables native isolation between tasks with Linux containers. It allows multi-resource scheduling (memory, CPU, disk, and ports). It uses Java, Python and C++ APIs to develop new parallel applications. It uses WebUI to view cluster statistics. It allows high resource utilization. It helps handling mixed workloads. It provides an easy-to-use container orchestration right out of the box. It ships binaries for different components (e.g. master, slaves, frameworks, etc.), which we can bind together to create our Mesos cluster. Components MasterMaster nodes are the brain of the cluster and provide a single source of truth for running tasks. There is one active master node at any point in time. The master node mediates between schedulers and slaves. Slaves advertise their resources to the master node, then the master node forwards them to the scheduler. Once the scheduler accepts the offer, it sends the task to run on the slave to the master, and the master forwards these tasks to the slave. SlaveSlaves manage resources at each machine level and execute the tasks submitted via the scheduler. FrameworksFrameworks are distributed applications that solve a specific use case. They consist of a scheduler and an executor. The scheduler gets a resource offer, which it can accept or decline. The executor runs the job on the slave, which the scheduler schedules. There are many existing frameworks and we can also create custom ones. Some of the existing frameworks are: Hadoop, Spark, Marathon, Chronos, Jenkins, Aurora, and many more. Executor Executors are used to run jobs on slaves. They can be shell scripts, Docker containers, and programs written in different languages (e.g. Java). Mesosphere DC/OSConcept“Mesosphere Enterprise DC/OS, offers a one-click install and enterprise features like security, monitoring, user interface, etc. on top of Mesos. By default, DC/OS comes with the Marathon framework and others can be added as required.” FeaturesThe Marathon framework has the following features: It starts, stops, scales, and updates applications. It has a nice web interface, API. It is highly available, with no single point of failure. It uses native Docker support. It supports rolling deploy/restart. It allows application health checks. It provides artifact staging. In addition to the Mesos features presented on the previous page, DC/OS provides the following ones: It provides an easy-to-use container orchestration right out of the box. It can configure multiple resource isolation zones. It can support applications with multiple persistent and ephemeral storage options. It allows you to install both public community and private community packaged applications. It allows you to manage your cluster and services using the web and command line interfaces. It allows you to easily scale up and scale down your services. It provides automation for updating services and the systems with zero downtime. Its Enterprise edition provides centralized management, control plane for service availability and performance monitoring. ComponentsThe DC/OS Master has the following default components: Mesos Master ProcessIt is similar to the master component of Mesos. Mesos DNSIt provides service discovery within the cluster, so applications and services running inside the cluster can reach to each other. MarathonIt is a framework which comes by default with DC/OS and provides the init system. ZooKeeperIt is a high-performance coordination service that manages the DC/OS services. Admin RouterIt is an open source Nginx configuration created by Mesosphere, providing central authentication and proxy to DC/OS services within the cluster. The DC/OS Agent nodes have the following components: Mesos Agent ProcessIt runs the mesos-slave process, which is similar to the slave component of Mesos. Mesos ContainerizerIt provides lightweight containerization and resource isolation of executors, using Linux-specific functionality, such as cgroups and namespaces. Docker ContainerIt provides support for launching tasks that contain Docker images. DC/OS has its own command line and web interfaces, and comes with a simple packaging and installation. NomadConcept“HashiCorp Nomad is a cluster manager and resource scheduler from HashiCorp, which is distributed, highly available, and scales to thousands of nodes. It is especially designed to run microservices and batch jobs, and it supports different workloads, like containers (Docker), VMs, and individual applications. It is also capable of scheduling applications and services on different platforms like Linux, Windows and Mac.” Features It handles both cluster management and resource scheduling. It supports multiple workloads, like containers (Docker), VMs, unikernels, and individual applications. It has multi-datacenter and multi-region support. We can have a Nomad client/server running in different clouds, which form the same logical Nomad cluster. It bin-packs applications onto servers to achieve high resource utilization. In Nomad, millions of containers can be deployed or upgraded by using the job file. It provides a built-in dry run execution facility, which shows the scheduling actions that are going to take place. It ensures that applications are running in failure scenarios. It supports long-running services, as well as batch jobs and cron jobs. It provides a built-in mechanism for rolling upgrades. Blue-green and canary deployments can be deployed using a declarative job file syntax. If nodes fail, Nomad automatically redeploys the application from unhealthy nodes to healthy nodes. NomadFileIt is distributed as a single binary, which has all of its dependency and runs in a server and client mode. To submit a job, the user has to define it using a declarative language called HashiCorp Configuration Language (HCL) with its resource requirements. Once submitted, Nomad will find available resources in the cluster and run it to maximize the resource utilization. Amazon ECSConcept“Amazon Elastic Container Service (Amazon ECS) is part of the Amazon Web Services (AWS) offerings. It provides a fast and highly scalable container management service that makes it easy to run, stop, and manage Docker containers on a cluster.” It can be configured in the following two launch modes: Fargate Launch Type AWS Fargate allows us to run containers without managing servers and clusters. In this mode, we just have to package our applications in containers along with CPU, memory, networking and IAM policies. We don’t have to provision, configure, and scale clusters of virtual machines to run containers, as AWS will take care of it for us. EC2 Launch Type With the EC2 launch type, we can provision, patch, and scale the ECS cluster. This gives more control to our servers and provides a range of customization options. Features It is compatible with Docker. It provides a managed cluster, so that users do not have to worry about managing and scaling the cluster. The task definition allows the user to define the applications through a .json file. Shared data volumes, as well as resource constraints for memory and CPU, can also be defined in the same file. It provides APIs to manage clusters, tasks, etc. It allows easy updates of containers to new versions. The monitoring feature is available through AWS CloudWatch. The logging facility is available through AWS CloudTrail. It supports third party Docker Registry or Docker Hub. AWS Fargate allows you to run and manage containers without having to provision or manage servers. AWS ECS allows you to build all types of containers. You can build a long-running service or a batch service in a container and run it on ECS. You can apply your Amazon Virtual Private Cloud (VPC), security groups and AWS Identity and Access Management (IAM) roles to the containers, which helps maintain a secure environment. You can run containers across multiple availability zones within regions to maintain High Availability. ECS can be integrated with AWS services like Elastic Load Balancing, Amazon VPC, AWS IAM, Amazon ECR, AWS Batch, Amazon CloudWatch, AWS CloudFormation, AWS CodeStar, AWS CloudTrail, and more. Components ClusterIt is a logical grouping of tasks or services. With the EC2 launch type, a cluster is also a grouping of container instances. Container InstanceIt is only applicable if we use the EC2 launch type. We define the Amazon EC2 instance to become part of the ECS cluster and to run the container workload. Container AgentIt is only applicable if we use the Fargate launch type. It allows container instances to connect to your cluster. Task DefinitionIt specifies the blueprint of an application, which consists of one or more containers. SchedulerIt places tasks on the cluster. ServiceIt allows one or more instances of tasks to run, depending on the task definition. TaskIt is a running container instance from the task definition. ContainerIt is a Docker container created from the task definition. AmazonEC2File","link":"/2019/07/16/Introduction to Cloud Infrastructure Technologies(6) Container Orchestration/"}],"tags":[{"name":"ANN","slug":"ANN","link":"/tags/ANN/"},{"name":"Introduction","slug":"Introduction","link":"/tags/Introduction/"},{"name":"Virtualization","slug":"Virtualization","link":"/tags/Virtualization/"},{"name":"IaaS","slug":"IaaS","link":"/tags/IaaS/"},{"name":"PaaS","slug":"PaaS","link":"/tags/PaaS/"},{"name":"Microservices","slug":"Microservices","link":"/tags/Microservices/"},{"name":"Unikernels","slug":"Unikernels","link":"/tags/Unikernels/"},{"name":"Micro OSes","slug":"Micro-OSes","link":"/tags/Micro-OSes/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"GitHub Pages","slug":"GitHub-Pages","link":"/tags/GitHub-Pages/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"}],"categories":[{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Cloud Computing","slug":"Cloud-Computing","link":"/categories/Cloud-Computing/"},{"name":"Configuration","slug":"Configuration","link":"/categories/Configuration/"}]}