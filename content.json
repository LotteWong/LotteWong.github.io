{"pages":[{"title":"About Me","text":"程序员小黄，会吃福建人的广东人，面临90后中年危机，爱的人都叫夏洛特。","link":"/about/index.html"}],"posts":[{"title":"#Golang# Golang与并发编程(4) Channel使用","text":"本文主要讨论 channel 使用的相关内容。 目录 Table of Contents 前情提要 为了实现 goroutine 通信，有两种常见并发模型： 共享内存：使用共享内存方式，Go 中 sync 库包提供了多种同步的机制。 消息队列：使用类似管道和消息队列的方式，各个并发单元数据相互独立，通过消息进行数据交换，Go 中 channel 类型模拟了这种同步的模式。 让我们再一次来复读 Go 社区的并发口号——“不要通过共享内存来通信，而应该通过通信来共享内存”。 本文将讨论 Go 并发编程中的通信桥梁 channel的使用，如有错漏，欢迎指出 ;P 概念引申管道 Pipe 管道 (Pipe) 是操作系统中进程间通信的一种方式。管道的本质是一个存在于内存或文件系统的缓冲有限的特殊文件，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序地将数据写入缓冲区，另一端的进程则顺序地读出数据。 匿名管道没有名字，是半双工的；匿名管道对于管道两端的进程而言是一个存在于内存的特殊文件；匿名管道只能用于父子进程或兄弟进程之间通信。 有名管道拥有名字，是全双工的；有名管道对于管道两端的进程而言是一个存在于文件系统的特殊文件；有名管道可以用于本机任意两个进程之间通信。 管道传送无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式。 消息队列 Message 消息队列 (Message) 是操作系统中进程间通信的一种方式。管道的本质是一个存放在内核中的长度不限的消息链表，一般遵循先进先出规则，也可以随机或按消息的类型查询，并且允许一个或多个进程向它写入或读取消息。 消息队列由消息队列标识符标识，提供有格式字节流并且具有类型。 信道 Channel 信道 (Channel) 是 Golang 中协程间通信的一种方式。信道的本质是一个线程安全的先进先出队列，可选择无缓冲或有缓冲，任意时刻同时只能有一个 goroutine 访问 channel。 信道可以指定类型。 channel 使用创建12345678// 双向channelch := make(chan T, cap)// 只读channel（但是没什么意义，双向channel可以赋值单向channel）ch_or := make(&lt;-chan T, cap)// 只写channel（但是没什么意义，双向channel可以赋值单向channel）ch_ow := make(chan&lt;- T, cap) 引用类型，使用 make 创建，零值为 nil 可选择数据类型 可选择缓冲容量 无缓冲：cap = 0，读写同步 有缓冲：cap &gt; 0，读写异步 可选择通信方向 只读：&lt;-chan 只写：chan&lt;- 读写1data := &lt;- ch 从 channel 中读取数据： 无缓冲：没有 goroutine 写入，channel 阻塞 有缓冲：channel 容量变空，channel 阻塞 1ch &lt;- data 向 channel 里写入数据： 无缓冲：没有 goroutine 读取，channel 阻塞 有缓冲：channel 容量变满，channel 阻塞 关闭123456789101112131415161718192021// 关闭 channel// close 手动关闭或等待自动 GCclose(ch)// 尝试写入已关闭的 channel// 导致 panic 异常ch &lt;- d// 返回数据或零值// 还有剩余数据则返回数据// 没有剩余数据则返回零值d := &lt;-ch// 返回数据和布尔值// true 表示成功从 channel 接收到值// false 表示 channel 已经被关闭并且里面没有值可接收d, ok := &lt;-ch// 尝试重复关闭 channel// 导致 panic 异常close(ch) 关闭 channel 可以通过显式的代码关闭或隐式的垃圾回收 对关闭后的 channel 进行写入操作： 导致 panic 异常 对关闭后的 channel 进行读取操作： 存在已经发送成功的数据：返回数据 不存在已经发送成功的数据：返回零值 对关闭后的 channel 进行重复关闭： 导致 panic 异常 close 常常与 select、range 和 defer 一起使用 PS：Golang 并不支持无限容量的 channel，原因是如果生产速率远远大于消费速率，那么 channel 内的数据不断累积将会爆掉内存。 应用实例单生产者-单消费者模型1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( \"fmt\" \"time\")const BUFLEN = 5// 生产者func producer(ch chan&lt;- int) { d := 1 for { ch &lt;- d fmt.Println(\"Produce:\", d) d++ time.Sleep(1 * time.Second) // 生产者速率不宜过快 }}// 消费者func consumer(ch &lt;-chan int) { for { d := &lt;-ch fmt.Println(\"Consume:\", d) time.Sleep(2 * time.Second) // 消费者速率不宜过快 }}func main() { // 生产消费的缓冲区 ch := make(chan int, BUFLEN) // 启动生产者协程 go producer(ch) // 启动消费者协程 go consumer(ch) // 防止主函数的退出 for { }} 多生产者-多消费者模型12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package mainimport ( \"fmt\" \"math/rand\" \"sync\" \"time\")const BUFLEN = 5var cond *sync.Cond = sync.NewCond(&amp;sync.Mutex{})// 生产者func producer(ch chan&lt;- int) { for { cond.L.Lock() for len(ch) == BUFLEN { cond.Wait() } data := rand.Intn(1000) ch &lt;- data fmt.Println(\"Produce:\", data) cond.L.Unlock() cond.Signal() time.Sleep(2 * time.Second) // 生产者速率不宜过快 }}// 消费者func consumer(ch &lt;-chan int) { for { cond.L.Lock() for len(ch) == 0 { cond.Wait() } data := &lt;-ch fmt.Println(\"Consume:\", data) cond.L.Unlock() cond.Signal() time.Sleep(1 * time.Second) // 消费者速率不宜过快 }}func main() { rand.Seed(time.Now().UnixNano()) // 生产消费的缓冲区 ch := make(chan int, BUFLEN) // 启动 10 个生产者协程 for i := 0; i &lt; 10; i++ { go producer(ch) } // 启动 10 个消费者协程 for i := 0; i &lt; 10; i++ { go consumer(ch) } // 防止主函数的退出 for { }} 参考链接 Go语言圣经 channel channel的应用","link":"/2020/03/06/Golang与并发编程(4)/"},{"title":"#Golang# Golang与并发编程(2) goroutine调度","text":"本文主要讨论 goroutine 调度的相关内容。 目录 Table of Contents 前情提要 Go 中的并发性是以 goroutine (独立活动)和 channel (用于通信)的形式实现的，这是因为 Go 所信奉的“不要通过共享内存来通信，而应该通过通信来共享内存”。当然，Go 也提供了对传统通信机制的支持，如 Mutex (互斥锁) 和 WaitGroup (信号量)。 本文将讨论 Go 并发编程中的基本单位 goroutine的调度，如有错漏，欢迎指出 ;P goroutine 调度 goroutines 仅存在于 go runtime 中而不存在于 OS 中，因此需要 Go Runtime Scheduler 来管理它们的生命周期。 线程模型 M：machine，一个 M 代表一个用户线程 P：processor，一个 P 代表一个 Go 协程所需的上下文环境 G：goroutine，一个 G 代表一个 Go 协程 KSE：kernel schedule entity，一个 KSE 代表一个内核线程 + 共享任务队列（Global Queue） 流程： Step1. 先开一个线程池； Step2. 每个线程不断从 Global Queue 中取 G 执行，亦即一个线程非同时刻可以执行多个协程； Step3. 如果没有系统调用、I/O 中断或者 channel 阻塞，goroutine 对应的线程正常工作；如果有系统调用、I/O中断或者 channel 阻塞，goroutine 对应的线程将被阻塞。 问题： 线程每次取 G 时需要加锁，否则出现竞态危害； goroutine 本身可以被阻塞，goroutine 对应的线程不应该被阻塞。 解决： 引入独有任务队列，每个线程只读自己的任务队列，不存在资源竞争； 发生系统调用或I/O中断的 goroutine 对应的线程要记录 goroutine 的上下文； 发生系统调用或I/O中断的 goroutine 对应的线程可以换出该 goroutine，然后执行新 goroutine。 + 独有任务队列（Local Queue） 流程： Step2. 每个线程不断从 Local Queue 中取 G 执行，亦即一个线程非同时刻可以执行多个协程； 问题： 线程既要负责调度又要负责执行，性能下降。 解决： 引入一个负责线程调度的抽象层，也就是 M。 + 线程调度器（M） 流程： Step1. 线程池中每个线程对应一个 M，M 将根据调度算法选择合适的 G 交由内核线程执行。 问题： 到目前为止，goroutine 仍然是协作式的，这意味着一个 G 可以长时间占用 CPU，直到它完成任务或被阻塞。 解决： 引入一个负责资源分配的抽象层，也就是 P。 + 抢占式（P） 流程： Step3.当一个 G 占用一定的 CPU 时间，又没有被调度过，那么它将被 runtime 抢占。 问题： 保留了 Global Queue 承载 Local Queue 溢出的 G，此时如果多个 P 同时访问 Global Queue，还是要加全局锁。 解决： 引入全局调度器 Sched。 + 全局调度器（Sched） P 主要负责 Local Queue 的调度，Sched 主要负责 Global Queue 的调度。 + 非阻塞（netpoller） 阻塞的 IO 模型为：G1 被阻塞后，M1 也被阻塞，但是 M1 的其它 G# 可以转移到空闲或新起的 M# 中执行。 非阻塞的 IO 模型为：G1 被阻塞后，M1 不会阻塞，M1 的其它 G# 仍然可以执行。 此外，netpoller 还抽象了 epoll 的多路复用，netpoller 将对应的文件描述符注册到 epoll 实例中进行 epoll_wait，就绪的文件描述符回调通知给阻塞的 G，G 更新为就绪状态等待调度继续执行。 调度场景 调度的本质就是 P 将 G 合理地分配给某个 M 的过程，M 只有和 P 绑定才能运行 G。 负载均衡 从本地到全局：Local Queue 满了，会将前一半的 G 和新创建的 G 放到 Global Queue 并打乱顺序； 从全局到本地：Local Queue 空了，会从 Glocal Queue 随机选取 n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2)) 个 G； 为了调度公平：1/61 的几率在 Global Queue 中找 G，60/61 的几率在 Local Queue 找 G，否则 Global Queue 中的 G 有可能永远没办法被调度。 任务窃取 出现空闲的M，此时它绑定的 P 的 Local Queue 为空，并且 Global Queue 也为空，则从其它 P 中窃取后一半的 G，这就是 work-stealing 算法。 线程自旋 在创建 G 时，运行的 G 会尝试唤醒其他空闲的 M 执行，如果没有 G，M 将自旋而不阻塞，不停地找 G； 自旋的优点是降低了 M 切换上下文的成本，缺点是 CPU 空转浪费资源； 折中方案是：最多有 GOMAXPROCS 个自旋的线程，多余的线程将休眠。 请求抢占 满足以下两个条件，sysmon 将会发送抢占请求，但是能否抢占成功不被保障： G 进行系统调用超过 20 μs G 运行 (非循环)超过 10 ms network IO / channel 阻塞 当 network IO / channel 操作发生，被阻塞的 G 放入等待队列，M 选择其它的 G ； 如果有就绪的 G，M 正常执行；如果无就绪的 G，M 将解绑 P 并且休眠； 当 network IO / channel 操作完成，被阻塞的 G 从等待变成就绪，加入某个 P 中被新的 M 执行或加入到 Global Queue，休眠的 M 将等待新创建的 G 唤醒。 在这个过程中，调度实际上是非阻塞的——M 不会因为 G 阻塞而休眠。 system call 阻塞 当 system call 操作发生，G 会阻塞，M 会解绑 P 并且休眠； 如果有空闲的 M，该空闲的 M 将绑定 P ，如果无空闲的 M，将新建一个 M 来绑定 P； 当 system call 操作完成，被阻塞的 G 从阻塞变成就绪，加入某个 P 中被新的 M 执行或加入到 Global Queue，休眠的 M 将等待新创建的 G 唤醒。 在这个过程中，调度实际上是阻塞的——M 会因为 G 阻塞而休眠 参考链接 Go并发编程-Goroutine如何调度的? Go调度器系列（3）图解调度原理 一文摸清 Go 的并发调度模型 也谈goroutine调度器","link":"/2020/03/04/Golang与并发编程(2)/"},{"title":"#Golang# Golang与并发编程(1) goroutine使用","text":"本文主要讨论 goroutine 使用的相关内容。 目录 Table of Contents 前情提要 Go 中的并发性是以 goroutine (独立活动)和 channel (用于通信)的形式实现的，这是因为 Go 所信奉的“不要通过共享内存来通信，而应该通过通信来共享内存”。当然，Go 也提供了对传统通信机制的支持，如 Mutex (互斥锁) 和 WaitGroup (信号量)。 本文将讨论 Go 并发编程中的基本单位 goroutine的使用，如有错漏，欢迎指出 ;P 概念辨析串行、并发与并行串行 CPU按顺序执行完一个线程后，才能开始另一个线程（显然不是同时执行）。 并发 CPU在各个任务间切换，同时刻一个CPU只能运行一个线程（看起来的同时执行）。 并行 同时刻多个任务在多个CPU上运行（事实上的同时执行）。 进程、线程与协程进程 进程是操作系统资源分配的最小单位。 进程具有独立的地址空间，通信需要通过IPC。 一个系统内的多个进程可以并发执行。 线程 线程是操作系统调度执行的最小单位。 线程共享进程的地址空间，通信直接共享内存。 一个进程内的多个线程可以并发执行。 协程 协程运行在用户态，而进程和线程都运行在内核态。 协程是函数间切换不是线程间切换，占用内存和切换开销更小。 一个线程内的多个协程只可串行执行。 PS：Linux虚拟地址空间布局 用户线程与内核线程 内核可见：用户线程对于内核来说是透明的，用户线程数量几乎不受限；内核线程对于内核来说是可见的，内核线程数量是有限制的。 调度实体：用户线程由应用程序或运行时调度器调度，用户线程切换只发生在用户态；内核线程由内核调度，内核线程切换需要陷入内核态。 资源竞争：用户线程在进程内竞争资源，用户线程阻塞那么对应进程阻塞，其它线程同时阻塞；内核线程在系统内竞争资源，内核线程阻塞只会阻塞该个线程，其它线程不被影响。 并行支持：使用用户线程，CPU 的执行单位为进程，要并行就要多进程；使用内核线程，CPU 的执行单位为线程，要并行只需多线程。 PS：线程实现模型 goroutine 与 coroutine goroutine 的运行机制属于抢占式任务处理，应用程序对CPU的控制由 Go Runtime Scheduler 管理；coroutine 的运行机制属于协作式任务处理，应用程序对CPU的控制由应用程序决定。 goroutine 可以并行执行，可能发生在多线程环境下；coroutine 始终顺序执行，总是发生在单线程环境下。 goroutine 使用 channel 通信；coroutine 使用 yield 和 resume 通信。 goroutine 使用main goroutine Golang 的入口函数 main() 本身就是个 goroutine： 123func main() { // ...} normal goroutine 创建一个普通的 goroutine，只需要在函数前加关键字 go： 12345678910111213func sample() { // ...}func main() { // 命名goroutine go sample() // 匿名goroutine go func() { // ... }} PS：除了 main 可以打断 goroutine 执行外，各 goroutine 间是独立的。由于 goroutine 执行顺序无法确定，代码的逻辑要独立于调用的顺序。 要点总结 goroutine 是在语言层面就提供的，只需要关键字 go，使用非常方便。 参考链接 并发简略-概述 并发简略-对比并发模型 Go语言圣经","link":"/2020/03/03/Golang与并发编程(1)/"},{"title":"#Machine Learning# SCUT Machine Learning(3) 算法与工程","text":"本文主要讨论Machine Learning的基本步骤，包括以下两个部分： 优化与调参学 软件工程之戒 Machine Learning优化与调参学数据的预处理归一化标准化中心化正则化参数的初始化全零初始1self.theta = np.zeros((n, 1)) # 权重偏置 全一初始1self.theta = np.ones((n, 1)) # 权重偏置 随机初始1self.theta = np.random.random((n, 1)) # 权重偏置 正态初始123self.theta = np.random.normal(size=(n, 1)) # 权重偏置或self.theta = np.random.randn(n, 1) # 权重偏置 梯度下降选择 参考链接：深度学习最全优化方法总结比较（SGD，Adagrad，Adadelta，Adam，Adamax，Nadam） 经验之谈： 对于稀疏数据，尽量使用学习率可自适应的优化方法，不用手动调节，而且最好采用默认值。 SGD通常训练时间更长，但是在好的初始化和学习率调度方案的情况下，结果更可靠。 如果在意更快的收敛，并且需要训练较深较复杂的网络时，推荐使用学习率自适应的优化方法。 Adadelta，RMSprop，Adam是比较相近的算法，在相似的情况下表现差不多。 在想使用带动量的RMSprop，或者Adam的地方，大多可以使用Nadam取得更好的效果。 单样本 梯度下降速度最快，迭代计算时间最长 123456# 单样本梯度下降def sgd(self, X_array, y_array): for X_item, y_item in zip(X_array, y_array): X_single = X_item.reshape(1, -1) y_single = y_item.reshape(1, -1) self.update(X_single, y_single) 小批量 梯度下降速度适中，迭代计算时间适中 123456# 小批量梯度下降def mbgd(self, X_array, y_array, batch_size=64): for idx in range(0, X_array.shape[0], batch_size): X_batch = X_array[idx:idx+batch_size] y_batch = y_array[idx:idx+batch_size] self.update(X_batch, y_batch) 全样本 梯度下降速度最慢，迭代计算时间最短 123# 全样本梯度下降def fbgd(self, X_array, y_array): self.update(X_array, y_array) Adagrad 自定义学习率，后期更新很慢 123456789101112# Adagraddef adagrad(self, X_array, y_array): sigma = 1e-7 # 平滑项 for X_item, y_item in zip(X_array, y_array): X_single = X_item.reshape(1, -1) y_single = y_item.reshape(1, -1) grad = X_single.T.dot(self.model(X_single) - y_single) / 1 self.grad_sum = self.grad_sum + np.sum(grad * grad) dTheta = -self.eta * (grad / math.sqrt(self.grad_sum + sigma)) self.theta = self.theta + dTheta RMSprop 进化Adagrad，变种Adadelta 123456789101112# RMSpropdef adadelta(self, X_array, y_array): sigma = 1e-7 # 平滑项 gama = 0.5 # 冲顶项 for X_item, y_item in zip(X_array, y_array): X_single = X_item.reshape(1, -1) y_single = y_item.reshape(1, -1) grad = X_single.T.dot(self.model(X_single) - y_single) / 1 self.grad_sum = gama * self.grad_sum + (1 - gama) * np.sum(grad * grad) dTheta = -self.eta * (grad / math.sqrt(self.grad_sum + sigma)) Adadelta 自定义学习率，后期更新变快 1234567891011121314# Adadeltadef adadelta(self, X_array, y_array): sigma = 1e-7 # 平滑项 gama = 0.9 # 冲顶项 for X_item, y_item in zip(X_array, y_array): X_single = X_item.reshape(1, -1) y_single = y_item.reshape(1, -1) grad = X_single.T.dot(self.model(X_single) - y_single) / 1 self.grad_sum = gama * self.grad_sum + (1 - gama) * np.sum(grad * grad) dTheta = -self.eta * (grad / math.sqrt(self.grad_sum + sigma)) self.theta = self.theta + dTheta Adamax 简单范围的Adam，学习率有确定范围，参数比较平稳 123456789101112131415161718# Adamaxdef adamax(self, X_array, y_array): sigma = 1e-7 # 平滑项 u = 0.5 # 冲顶项 v = 0.5 # 冲顶项 for X_item, y_item in zip(X_array, y_array): X_single = X_item.reshape(1, -1) y_single = y_item.reshape(1, -1) grad = X_single.T.dot(self.model(X_single) - y_single) / 1 self.grad = u * self.grad + (1 - u) * grad self.grad_sum = np.maximum(v * self.grad_sum, np.sum(grad)) m_t_hat = self.grad / (1 - u) n_t_hat = self.grad_sum / (1 - v) dTheta = - self.eta / (n_t_hat + sigma) * m_t_hat self.theta = self.theta + dTheta Adam 带动量项的RMSprop，学习率有确定范围，参数比较平稳 123456789101112131415161718# Adamdef adam(self, X_array, y_array): sigma = 1e-7 # 平滑项 u = 0.5 # 冲顶项 v = 0.5 # 冲顶项 for X_item, y_item in zip(X_array, y_array): X_single = X_item.reshape(1, -1) y_single = y_item.reshape(1, -1) grad = X_single.T.dot(self.model(X_single) - y_single) / 1 self.grad = u * self.grad + (1 - u) * grad self.grad_sum = v * self.grad_sum + (1 - v) * np.sum(grad * grad) m_t_hat = self.grad / (1 - u) n_t_hat = self.grad_sum / (1 - v) dTheta = - self.eta * (m_t_hat / (math.sqrt(n_t_hat) + sigma)) self.theta = self.theta + dTheta 软件工程之戒模块函数","link":"/2019/11/04/SCUT机器学习 (3) 算法与工程/"},{"title":"#Machine Learning# SCUT Machine Learning(2) 训练、测试与可视化","text":"本文主要讨论Machine Learning的基本步骤，包括以下三个部分： 训练的三部曲 测试的验证法 数据的可视化 Machine Learning训练的三部曲Step 1: ModelStep 2: Goodness of FunctionStep 3: Best Function合并更新参数123456# 更新参数：梯度下降def update(self, X, y): m = X.shape[0] # 标签个数 dTheta = X.T.dot(self.model(X) - y) / m self.theta = self.theta - self.eta * dTheta 分开更新参数123456789# 更新参数：梯度下降def update(self, X, y): m = X.shape[0] # 标签个数 dZ = self.model(X) - y dW = X.T.dot(dZ) / m db = dZ.sum(axis=0, keepdims=True) / m self.W = self.W - self.eta * dW self.b = self.b - self.eta * db 测试的验证法损失值准确率回归问题1# pass 分类问题1234567891011121314# 数据的准确率def accuracy(self, X, y, threshold): y_pred = self.predict(X_test, threshold) y_true = y right = 0 total = y_pred.shape[0] for i in range(total): if y_pred[i] == y_true[i]: right += 1 acc = right / total return str(acc * 100) 数据的可视化损失值123456789# 数据的可视化def visualize(self, iter_list, loss_list): plt.figure('program title') plt.title('chart title') ax = plt.gca() ax.set_xlabel('epoch') ax.set_ylabel('loss') ax.plot(iter_list, loss_list, color='r', linewidth=1, alpha=0.6) plt.show()","link":"/2019/11/04/SCUT机器学习 (2) 训练、测试与可视化/"},{"title":"#Machine Learning# SCUT Machine Learning(1) 数据与参数","text":"本文主要讨论Machine Learning的基本步骤，包括以下两个部分： 读取处理数据 初始化各参数 Machine Learning读取处理数据本地数据合并更新参数123456789101112131415local_file = '$local_dataset_path'def load_data(path): # 读取本地原始数据集 raw_data = datasets.load_svmlight_file(path) # 返回scipy.matrix 或 raw_data = datasets.load_files(path) # 返回numpy.ndarray # 分开处理特征和标签 X, y = np.c_[raw_data[0].A, np.ones((raw_data[0].shape[0], 1))], raw_data[1].reshape(-1, 1) 或 X, y = np.c_[raw_data[0], np.ones((raw_data[0].shape[0], 1))], raw_data[1].reshape(-1, 1) # 切分训练集和验证集 return model_selection.train_test_split(X, y, test_size=0.3, random_state=0) 分开更新参数123456789101112131415local_file = '$local_dataset_path'def load_data(path): # 读取本地原始数据集 raw_data = datasets.load_svmlight_file(path) # 返回scipy.matrix 或 raw_data = datasets.load_files(path) # 返回numpy.ndarray\"\"\" # 分开处理特征和标签 X, y = raw_data[0].A, raw_data[1].reshape(-1, 1) 或 X, y = raw_data[0], raw_data[1].reshape(-1, 1) # 切分训练集和验证集 return model_selection.train_test_split(X, y, test_size=0.3, random_state=0) 网络数据合并更新参数1# pass 分开更新参数1# pass 随机抽样1234567891011121314# 随机抽样def random_select(self, X, y, sample_size=1024): m = X.shape[0] # 标签个数 i_list = random.sample([idx for idx in range(n)], batch_size) # 下标序列 X_list = [] y_list = [] for i in i_list: X_list.append(X[i]) y_list.append(y[i]) X_array = np.array(X_list) y_array = np.array(y_list) return X_array, y_array 初始化各参数不抽样合并更新参数123456# 加载参数def __init__(self, eta, epo, batch_size, n): self.eta = eta # 学习速率 self.epo = epo # 迭代次数 self.batch_size = batch_size # 批处理量 self.theta = np.zeros((n, 1)) # 权重偏置 分开更新参数1234567# 加载参数def __init__(self, eta, epo, batch_size, n): self.eta = eta # 学习速率 self.epo = epo # 迭代次数 self.batch_size = batch_size # 批处理量 self.W = np.zeros((n, 1)) # 权重参数 self.b = 0 # 偏置参数 要抽样合并更新参数1234567# 加载参数def __init__(self, eta, epo, sample_size, batch_size, n): self.eta = eta # 学习速率 self.epo = epo # 迭代次数 self.sample_size = sample_size # 抽样大小 self.batch_size = batch_size # 批处理量 self.theta = np.zeros((n, 1)) # 权重偏置 分开更新参数12345678# 加载参数def __init__(self, eta, epo, sample_size, batch_size, n): self.eta = eta # 学习速率 self.epo = epo # 迭代次数 self.sample_size = sample_size # 抽样大小 self.batch_size = batch_size # 批处理量 self.W = np.zeros((n, 1)) # 权重参数 self.b = 0 # 偏置参数","link":"/2019/11/04/SCUT机器学习 (1) 数据与参数/"},{"title":"#WSL# WSL从入门到...(1) WSL 1 vs WSL 2","text":"对比适用于 Linux 的 Windows 子系统（Windows Subsystem for Linux, WSL）的两个版本 - WSL 1 和 WSL 2 ，主要分为以下六个部分： 前情提要 相关简介 性能对比 架构对比 几点总结 参考链接 目录 Table of Contents 前情提要 前阵网上冲浪围观 M$ Build 2019 的 WSL Session ，感受了一波 Microsoft ❤ Open Source，遂决定根据讲座和文档内容当一次复读机讨论一下 WSL ( 啊我的塑料英语_(:з)∠)_。 相关简介 The Windows Subsystem for Linux lets developers run a GNU/Linux environment – including most command-line tools, utilities, and applications – directly on Windows, unmodified, without the overhead of a virtual machine. 适用于 Linux 的 Windows 子系统（Windows Subsystem for Linux, WSL）可以简单地理解为在 Windows 上提供了运行 Linux 的平台。由于是 Subsystem ，与裸机装 Linux Distribution 相比，存在功能限制和性能打折的情况。 You can: …… Invoke Windows applications using a Unix-like command-line shell. Invoke GNU/Linux applications on Windows. …… 对于懒得开虚拟机or装双系统 + ECS渣渣级配置 + 非尊贵苹果用户而言， WSL 还是很有吸引力的 (虽然也很多坑。除了对 Linux 本身有需求外，上面提到的 Windows 和 Linux 互相invoke 也很有意思， WSL 因此大大降低了原本配置两个文件系统的繁琐程度。 性能对比 WSL 2 相比 WSL 1，主要优化了访问文件系统的速度以及提供了更完整的系统调用接口。 File system performance Full system call compatibility 架构对比 WSL 1 WSL 1 的大体思路是，在一台 Windows 主机上安装 Linux 发行版本，依赖中间层的驱动器完成 Linux Namespace 和 Windows Kernel 之间的通信捕获和指令翻译（比如 path 和 flag ），作用范围包括但不局限于系统调用、文件系统、权限管理和网络配置等。 这样的设计存在一些缺陷： 某些翻译无可避免地需要付出时空代价，甚至由于两种内核的设计思想存在冲突而无法进行。 由于 Linux Kernel 更新得非常快，单靠 M$ Team 自己实现翻译，开发进度远远滞后于实际生产需求。 【更多详见 👉 WSL从入门到…(2) Dive into WSL 1】 WSL 2 WSL 2 的大体思路是，开启 Hyper-V 功能，Windows Hyper-V Container（包含Windows Kernel和Windows Usermode）持续运行，Linux Hyper-V Container（包含Linux Kernel和Linux Usermode）随用随开，两者通过 Socket 通信。 这样的设计存在一些缺陷： 需要处理器提供虚拟化选项，一些 arm64 架构的芯片不支持该功能。 Windows 开Hyper-V后将无法同时运行 VMware 和 Virtual Box 等工具，因为它们都要求独占 Hypervisor 才能够运行。 虚拟化伴随一系列一致性问题，比如权限管理和网络配置等等。 【更多详见 👉 WSL从入门到…(3) Dive into WSL 2】 Linux Kernel 用 Linux Kernel 是为了解决 WSL 1 的遗留问题（“Uses real Linux kernel for improved performance and perfect compatibility”），翻译不好搞就“拿来主义”。 M$ 甚至为 WSL 2 定制了 Linux Kernel (没想到吧.jpg Virtualization 要使两种内核能够共存最直接的思路就是使用虚拟化技术，而 WSL 2 采用了一种有别于传统虚拟机和新兴容器的新(?)方法 - Lightweight utility VM，其特点是集成度高（关联 Windows 服务）且只在运行时启动（否则被销毁回收）。 相比传统虚拟机，内存占用更小、启动速度更快以及可以同时运行更多实例。 相比新兴容器，基于 Hyper-V 面向 server 场景，本质还是 VM ，隔离得更彻底。 几点总结 根据PM的说法， WSL 1 和 WSL 2 会并行维护，既适用于桌面版也可以运行在服务器。下面简单回顾两者的区别： WSL 1 WSL 2 核心技术 Pico provider drivers Lightweight utility VM 同一实例（Container） ✓ ✗ 额外支持（虚拟化） ✗ ✓ 文件系统 访问慢 访问快 系统调用 缺少 完整 权限管理 相同 不同 网络配置 相同 不同 后续两节将分别再深入介绍 WSL 1 和 WSL 2 的实现细节。那么我先占坑逃了（（（ 参考链接 The new Windows subsystem for Linux architecture: a deep dive Windows Subsystem for Linux Documentation","link":"/2019/12/12/WSL从入门到...(1)/"},{"title":"#Git# 速查手册：常用 Git 命令","text":"覆盖在学习和工作中的常用 Git 命令：配置 / 仓库 / 查看 / 暂存 / 提交 / 回退 / 克隆 / 拉取 / 推送 / 合并 / 冲突 / 分支 / 标签 / 工具 目录 Table of Contents 配置账号1234567891011# 配置多个本地用户的账号# 全局级git config --global user.name \"${user_name}\"git config --global user.email \"${user_email}\"# 仓库级# git config --global --unset user.name \"${user_name}\"# git config --global --unset user.name \"${user_email}\"git config --local user.name \"${user_name}\"git config --local user.email \"${user_email}\" 密钥1234567891011121314151617181920# 配置多个远程仓库的密钥# 生成密钥ssh-keygen -t rsa_githubssh-keygen -t rsa_gitlab# 配置密钥vim ~/.ssh/configHost github.comHostName github.comUser gitIdentityFile ~/.ssh/rsa_github Host gitlab.comHostName gitlab.comUser gitIdentityFile ~/.ssh/rsa_gitlab:wq 仓库查看1git remote -v 新建12# Example: git remote add origin git@github.com:LotteWong/lottewong.github.io.gitgit remote add ${origin_name} git@host:/path/to/registry.git 删除1git remote rm ${origin_name} 查询当前状态1git status 差异分析工作区 vs 暂存区1git diff (${branch_name}) (${file}) # 默认 branch = current; file 若不填作用于全部文件 暂存区 vs 版本库1git diff --cached (${commit_id}) (${file}) # 默认 commit = HEAD; file 若不填作用于全部文件 工作区 vs 版本库1git diff ${commit_id} (${file}) # file 若不填作用于全部文件 版本库 vs 版本库1git diff ${commit_id} ${commit_id} (${file}) # file 若不填作用于全部文件 提交记录123git log # 详细git log --oneline # 简略git log --graph # 图示 操作记录1git reflog 暂存查看1git stash list 保存1git stash 恢复12git stash pop # 默认还原栈顶数据git stash pop stash@{${id}} # 指定还原特定数据 删除12git stash clear # 删除全部暂存数据git stash drop stash@{${id}} # 删除指定暂存数据 提交暂存区123git add -A or git add --all # 提交整个仓库全部文件(New/Modified/Deleted)git add /path/to/file # 提交指定目录全部文件(New/Modified/Deleted)git add -u # 提交整个仓库已有文件(Modified/Deleted) 版本库123git commit -m \"${commit_message}\" # 指定提交信息标题git commit # 打开默认的编辑器git commit --amend # 追加提交 回退工作区12git reset --hard (${commit_id}) (${file}) # 默认 commit = HEAD; file 若不填作用于全部文件# git checkout ${commit_id} ${file} 暂存区12git reset (--mixed) (${commit_id}) (${file}) # 会清除暂存区; 默认 commit = HEAD; file 若不填作用于全部文件# git checkout ${commit_id} ${file} 版本库1234567# 向前移动指针git reset --soft (${commit_id}) (${file}) # 不清除暂存区; 默认 commit = HEAD; file 若不填作用于全部文件# git checkout ${commit_id} ${file}# 向后移动指针git revert (${commit_id}) # 默认 commit = HEAD; 撤销单次提交并生成单次提交git revert -n ${old_commit}^..${new_commit} # 撤销连续提交并生成单次提交 克隆12345# Example: git clone git@github.com:LotteWong/lottewong.github.io.gitgit clone git@host:/path/to/registry.git # 克隆默认分支# Example: git clone -b backup git@github.com:LotteWong/lottewong.github.io.gitgit clone -b ${branch_name} git@host:/path/to/registry.git # 克隆指定分支 拉取123456git pull origin ${remote_branch} # 拉取到已有本地分支git checkout -b ${local_branch}:${remote_branch} # 拉取并新建本地分支git fetch origin ${remote_branch}git pull origin ${remote_branch} # git fetch + git mergegit pull origin --rebase ${remote_branch} # git fetch + git rebase 推送12git push origin ${remote_branch} # 推送到已有远程分支git push origin ${local_branch}:${remote_branch} # 推送并新建远程分支 合并Merge1234git merge ${branch_name} # 带有单独合并提交信息git merge ${branch_name} --no-commit # 不带单独合并提交信息git merge --continue # 解决冲突后使用git merge --abort # 不打算解决冲突 Squash1234git merge --squash ${branch_name} # A1 → B1 → M3git rebase -i ${startpoint} (${endpoint}) # A1 → B1 → C2 → D2; 默认 endpoint = HEAD# pick(p)：保留本次提交# squash(s)：合并前后提交 Rebase123git rebase ${branch_name}git rebase --continue # 解决冲突后使用git rebase --abort # 不打算解决冲突 Cherry-Pick123git cherry-pick ${commit_id}git cherry-pick --continue # 解决冲突后使用git cherry-pick --abort # 不打算解决冲突 冲突1234git status # 查看冲突文件vim /path/to/file # 解决冲突之处git add /path/to/file # 将文件加入暂存区git commit -m \"${commit_message}\" # 将文件加入版本库 分支查看123git branch -a # 全部分支git branch -v # 本地分支git branch -r # 远程分支 更新1git remote update 新建12git checkout -b ${local_branch}:${remote_branch} # 创建本地分支：远程分支 → 本地分支git push origin ${local_branch}:${remote_branch} # 创建远程分支：本地分支 → 远程分支 切换1git checkout ${branch_name} 删除123git branch -d ${local_branch} # 非强制删除本地分支git branch -D ${local_branch} # 强制性删除本地分支git push origin --delete ${remote_branch} # 删除远程分支 标签查看12git tag # 全部标签git show ${tag_name} # 指定标签 新建123git tag ${tag_name} (${commit_id}) # 创建本地标签; 默认 commit = HEADgit push origin --tags # 创建全部远程标签git push origin ${tag_name} # 创建指定远程标签 删除12git tag -d ${tag_name} # 删除本地标签git push origin --delete ${tag_name} 工具提交规范12345# 安装npm install -g commitizen cz-conventional-changelog# 使用git cz 变更日志12345# 安装npm install -g conventional-changelog-cli# 使用conventional-changelog -p angular -i CHANGELOG.md -s -r 0 代码评审 To be continued… 子级模块 To be continued…","link":"/2020/05/21/速查手册之常用Git命令/"},{"title":"#WSL# WSL从入门到...(3) Dive into WSL 2","text":"对 WSL 2 的一些实现细节进行补充说明，主要分为以下五个部分： 前情提要 背景 架构与答疑 总结 参考链接 目录 Table of Contents 前情提要 前面已经简要介绍了 WSL 1 和 WSL 2 的区别，本节将聚焦于 WSL 2的实现细节。点开官方博客开始收获惊(da)喜(keng)，才疏学浅写错也不要打我 (预先感谢各位勘误 逃 【更多信息 👉 WSL从入门到…(1) WSL 1 vs WSL 2】 背景功能 …… still provides the same user experience as in WSL 1 (the current widely available version). 性能 Its primary goals are to increase file system performance, as well as adding full system call compatibility. 兼容 Individual Linux distros can be run either as a WSL 1 distro, or as a WSL 2 distro, can be upgraded or downgraded at any time, and you can run WSL 1 and WSL 2 distros side by side. 架构 工作流大概是： 启动 LXSS Manager Service 跟踪 Linux Distribution 的安装、运行和卸载。 启动 Host compute service 和 Host Network Service 创建和初始化 Lightweight utility VM 实例。 被封装好的（“shipping in box”）基于 Linux Kernel 的虚拟机运行。 LXSS Manager Service 映射、加载和管理 Linux Distribution 的文件系统。 以上准备工作完成后，wsl.exe 和 bash 之间将通过 socket 传递指令来完成作业。 PS: Lightweight utility VM 只会在需要时创建运行，如果 bash 或 wsl.exe 退出，一段时间后将会被回收。 访问 Windows 文件 Windows 主机启动一个文件服务器，此时 Linux 作为客户端发送请求，两者使用 9P 协议进行通信。 效果看起来像把 Windows 的 C 盘挂载到了 Linux 的 /mnt 目录下。访问 Linux 的 /mnt/c 就是在 访问 Window 的 C:\\ 。 PS: 特别地，如果在 bash 内启动 cmd.exe ，由于 Windows 和 Linux 的可执行文件格式不同（前者是 PE 或 PE32+ ，后者是 ELF32 或 ELF64），.exe 文件无法直接运行。WSL 2 的处理方法实际上是：Linux 下的 bash 向 wsl.exe 发送 Interop command，Windows 下的 wsl.exe 解析后启动 .exe 文件。 访问 Linux 文件 Linux 虚拟机启动一个文件服务器，此时 Windows 作为客户端发送请求，两者使用 9P 协议进行通信。 效果看起来像在 Windows 上开一般的虚拟机，对应的目录（在 Network 内）可以被文件资源管理器轻松地访问。 PS: 从上述中可见，WSL 2 访问文件的中心观点 —— “两个系统都做各自可以做 / 擅长做的事情，遇事不决就通过socket发指令吱一声，而不会选择简单粗暴地翻译。” 答疑 Q1: Microsoft 的 Linux Team 根据 WSL 2 针对 Linux Kernel 做了哪些调整？ A1: 首先，和 WSL 1 一样，WSL 2 本身并不提供 Linux 发行版本，用户需自行前往 Windows Store 下载或脚本安装自定义的发行版本；其次，WSL 2 的 Linux Kernel 基于稳定的 version 4.19，并在启动时间、内存占用和需支持设备数等方面都进行了相应的优化；最后， WSL 2 将通过 Windows 更新来推送新服务，并由 Microsoft 及其它专业的商业伙伴提供安全监控和保障。 Q2: 可以在虚拟机中使用 WSL 2 吗？ A2: 可以，但要确保开启 nested virtualization 选项（在 Windows PowerShell （以管理员身份运行）中输入 Set-VMProcessor -VMName &lt;VMName&gt; -ExposeVirtualizationExtensions $true 命令）。 Q3: WSL 1 中的配置文件 wsl.conf 在 WSL 2 中仍可以使用吗？ A3: 可以，比如自动挂载磁盘、开启或关闭 interop command和更改挂载目录等操作都将继续支持，更多 WSL 配置项可见 Distro Management 。 Q4: WSL 2 将支持 Docker 技术，WSL 2 的 Docker 会有什么特别的限制吗？ A4: 如果启动的是 Windows 的 Docker ，将按照 Window 的 Docker 工作；如果启动的是 Linux 的 Docker ，将按照 Linux 的 Docker 工作。尽管 Windows 的 Docker 和 Linux 的 Docker 实现方式有所出入（由于篇幅有限，将不展开说明），但原则上 WSL 2 不存在对 Docker 的特别限制。 Q5: 有没有针对 WSL 2 的硬件支持，比如访问并加速GPU并之类？ A5: 暂未完善，但持续开发中（但 WSL 1 支持串行端口和USB设备的访问，有需要可以先凑合用）。 Q6: 有没有统一 Windows 文件和 Linux 文件权限管理的解决方案？ A6: 在 WSL 1 中，因为是同一主机不存在系统边界（映射相对容易），权限管理是通过中间层的驱动器提供额外服务实现的；在 WSL 2 中，因为是不同主机而存在系统边界（映射相对困难），WSL 2 采取的策略是保持各自系统原有的访问权限，通过补充一些上层协议（比如 SSH）进行辅助管理，新的 Release 版本已经支持 “Sharing SSH keys between Windows and WSL 2“。 Q7: 有没有 WSL 2 对网络配置的支持？ A7: 在 WSL 1 中，因为是同一主机，网络出口的 IP 地址是相同的，相关操作也接近原生 ；在 WSL 2 中，因为是不同主机，网络出口的 IP 地址是不同的，WSL 2 计划实现的 Feature 包括：① 在提供不同的IP 地址情景下，加速网络访问；② 将客机映射到主机，共享同一 IP 地址；③ 尽快支持全部 Linux 下的网络应用。 总结 简单的理解：通过使用虚拟化技术，使得 Hypervisor 上同时运行 Windows 实例和 Linux 实例，Windows 实例占主导地位并且持续地运行，Linux 实例非常轻量级并且只有在用到时才会启动。采用原生的 Linux Kernel 保证了系统调用的完整性，9P 协议的注入又很好地解决了两个不同文件系统之间的交互问题。 参考链接 The new Windows subsystem for Linux architecture: a deep dive About WSL 2 Shipping a Linux Kernel with Windows WSL 2 Frequently Asked Questions","link":"/2019/12/14/WSL从入门到...(3)/"},{"title":"#Sucks# 写在二零二壹","text":"（（（假装有简介.jpg 过去的一年其实还蛮糟糕的（或者说下半年，但是也发生了很多美好的事情。因为很长一段时间都不写作了，感觉到既遗憾又气愤，所以这不会是一篇好随感，索性就像每日面对的客体一样，整齐划一地理清我的思绪。 2020 糟糕的事情： 做了一些无用功，并且最后也处理得不好 工作的时候学习变得零碎，休息的时候缺乏学习热情 身体感觉不好，作息不够规律，职业病少运动，摄入过多酒精 对事物开始冷感，不阅读不写作 工作的时候很自闭，休息的时候很肥宅 最近有点本末倒置，害怕看到了尽头 感觉自己有点病了，失去了生命力 2020 美好的事情： 遇到了很爱我、我很爱的她，并且我们有一只可爱的小猫咪 春招的 offer 收割机（bushi，对自己的一点点的肯定 拿到了满意的 offer，妈宝的胜利（逃 开始学习理财知识，一场有趣的游戏 ​总的来说，我讨厌 2020 原地踏步甚至拼命倒退的自己，并且这种想法还会越来越少，自己也不愿意走出舒适圈。与此同时，我感到灵魂中，已经少了许多纯粹，反而添了许多欲望。2021 希望自己健健康康、开开心心。 2021 Todo List： 重视身体情况，早睡早起，晚上回来可以做做运动，养生 午休前和睡觉前都可以读读书，多看电影多听新歌，坚持写日记 养成每天开始工作前关注新技术，结束工作后总结这一天的好习惯 周末要出去走走，要学习知识 工作时间不要分心其它事情，做好时间管理 和别人交往善良和热情，如果需要练习那么就去练习，但也要有自己的原则 不要拖延，想就去做，每天记录自己好的变化 希望新的一年除了工作以外，有一些新的关注点 ​Hope is a dangerous thing for a woman like me to have. Fake it till you make it.","link":"/2021/01/01/写在二零二壹/"},{"title":"#Sucks# 写在二零二零","text":"（（（无聊的吐槽与没多少意思的复读 生活大概就是，起落落落。 说来写前端也快一个月，虽然以后大概率也不会再专门帮别人写了，但是这个过程还是有不少心得体会，比如理解需求、读懂架构、实现逻辑、保证质量和通过测试之类的。因为开发得比较随心所欲，换句话说，就是还有很多成长的空间，非常感谢实验室的师兄师姐没有嫌弃我这个小菜🐓，黄老师还即将迎来人生第一桶金 (?) 要说后悔到印象深刻的事情，除了在GY咕咕掉了信息竞赛，选大数据可能也是之一。无非就是不会也不那么感兴趣，每次先被数据处理套路一阵，然后对着数学公式和神经网络敲敲敲，Debug没有机器也要来个地久天长，还要盯着AB榜患得患失，实在是搞不来啦。虽然但是，学算法这半年来最大的收获就是学会如何心平气和地把一件事情真正做得又快又好（我却还没有 过去一年搞了不少副业，真正有营养的却不多，从C++写到Dart，从全栈写到云计算…明白一个人的精力其实很有限，什么都干 ≈ 什么都没干。就算开了n个repo，混了n个project，挂了n个title，只要面对 Talk is cheap, show me the code 也会沉默。当然广度优先学习也没什么不好，只不过是我算力太弱了罢。到了三年级就不可避免地想东想西，不能再像从前一样说干就干，要考虑沉默成本，要面对同伴焦虑，决定去哪搬砖也要小心翼翼，还随时在敏捷和投机的边缘试探。最后说服了自己还是保持刮刮乐的心态…（刮到了云计算还挺幸运的 误 虽然以上都是些无关痛痒的吐槽，生活也还有它的复杂和美好，诸如和很长一段时间被gaslight的自己和解啦、第一次当PM啦、去M$RA蹭吃蹭喝啦、再见好X友发展革命情谊啦、无疾而终地暗恋过啦云云，这种时候还是要感慨年轻真好滴嘻嘻 :P 以前觉得生活本质就是和西西弗斯神话一样的，相当虚无。现在也还是这么觉得，不过直觉上有趣的事情那么多，每天一点点也足够快乐。一般来说，新年之交讲的东西都不能信，就不继续一本正经胡说八道了，最后以小波作结吧： “那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想再一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消失，最后变得像挨了锤的牛一样。可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。”","link":"/2020/01/01/写在二零二零/"},{"title":"#Linux&Shell# 速查手册：常用 Linux&Shell 命令","text":"覆盖在学习和工作中的常用 Linux 命令：管理 / 连接 / 网络 / 进程 / 文件 / 文本 目录 Table of Contents 管理列举123456# Ubuntuapt list --installed# CentOSyum list installed# Alpineapk info 更新12345678# Ubuntuapt-get updateapt-get -y upgrade# CentOSyum update# Alpineapk updateapk upgrade 安装123456# Ubuntuapt-get install -y ${package}# CentOSyum install -y ${package}# Alpineapk add --upgrade ${package} 卸载123456# Ubuntuapt-get --purge remove ${package}# CentOSyum remove ${package}# Alpineapk del ${package} 连接ssh12ssh -p ${port} ${username}@${host}sshpass -p ${password} ssh -p ${port} ${username}@${host} telnet1telnet ${host} ${port} ping1ping ${host} nslookup1nslookup ${domain} curl12345curl \\-X ${method} \\-H \"${header_key}: ${\"header_val\"}\" \\-d \"${json_data}\" \\${api_url} \\ mysql1mysql -h ${host} -P ${port} -u ${username} -p 网络查看 ip1ip a |grep eth 查看 dns1cat /etc/resolv.conf |grep nameserver 进程查询 proc1ps -ef |grep ${proc_name} 查询 port1lsof -i:${port} 从 proc 查 port / 从 port 查 proc12netstat -tunlp |grep ${proc_name}netstat -tunlp |grep ${port} 杀死进程12345678ps -ef | grep ${including_keyword} | grep -v ${excluding_keyword}kill -s 9 ${pid}ps -ef | grep ${including_keyword} | grep -v ${excluding_keyword} | awk '{print $2}' | xargs kill -s 9kill -s 9 `pgrep ${keyword}`pkill -9 ${keyword} 文件从服务器下载到本机12scp -r -P ${port} ${username}@${host}:/path/to/remote /path/to/local # 包括文件rsync -a -e ssh --exclude=\"${pattern}\" ${username}@${host}:/path/to/remote /path/to/local # 排除文件 从本机上传到服务器12scp -r /path/to/local -P ${port} ${username}@${host}:/path/to/remote # 包括文件rsync -a -e ssh --exclude=\"${pattern}\" /path/to/local ${username}@${host}:/path/to/remote # 排除文件 解压zip 1unzip -d /path/to/unzip ${pkg_to_unzip} tar 123tar -xvf ${pkg_to_untar} # 解压 tar 包tar -zxvf ${pkg_to_untar} # 解压 tar.gz 包tar -jxvf ${pkg_to_untar} # 解压 tar.bz2 包 加压zip 123zip -r /path/to/unzip ${pkg_to_zip}zip -d /path/to/zip ${file_to_delete} # 从压缩包中删除文件zip -m /path/to/zip ${file_to_append} # 向压缩包中添加文件 tar 123tar -cvf ${pkg_to_tar} # 加压 tar 包tar -zcvf ${pkg_to_tar} # 加压 tar.gz 包tar -zjvf ${pkg_to_tar} # 加压 tar.bz2 包 文本查看json 1cat ${file} | python -m json.tool log 1234less ${log_file}vim ${log_file}tail -n ${number} ${log_file}tail -f ${log_file} 编辑复制 1ctrl + Insert 粘贴 1shift + Insert 移动 1234gg # 首行G # 末行shift + ^ # 行首shift + $ # 行末 搜索 1234/pattern # 向前搜索？pattern # 向后搜索n # 上一个N # 下一个 查看缩进和行尾 1: set list 处理分隔 1awk -F:\"${seperator}\" '/${pattern}/${command}' ${file} 替换 1sed \"s/${pattern}/${substr}/g\"","link":"/2020/05/14/速查手册之常用Linux&Shell命令/"},{"title":"#Golang# Golang与并发编程(3) goroutine泄漏","text":"介绍 goroutine 泄漏的相关内容，主要讨论以下三个部分： goroutine 泄漏判断 goroutine 泄漏分类 goroutine 泄漏预防 目录 Table of Contents 前情提要 goroutine 泄漏指的是因为编码中的陷阱使得 goroutine 无法正常释放而造成的内存泄漏，甚至导致内存溢出或最终程序崩溃。 本文将讨论 goroutine泄漏的判断、分类和预防，如有错漏，欢迎指出 ;P goroutine泄漏判断runtime.NumGoroutine runtime.NumGoroutine 可以返回正在运行中的 goroutine 数量（包括 main goroutine 和 normal goroutine）。 12345678910import( \"fmt\" \"runtime\")// ...fmt.Println(runtime.NumGoroutine())// ... runtime/pprof runtime/pprof 可以（以写入的形式）返回 goroutine 的运行数量和堆栈信息。 12345678910import ( \"os\" \"runtime/pprof\" )// ...pprof.Lookup(\"goroutine\").WriteTo(os.Stdout, 1)// ... http/net/pprof http/net/pprof 可以（以访问的形式）返回 goroutine 的运行数量、堆栈信息和其它资源信息。 123456789101112import ( \"net/http\" _ \"net/http/pprof\" )// ...http.ListenAndServe(\"localhost:6060\", nil)// ...// 进入 http://localhost:6060/debug/pprof/goroutine?debug=1 查看 gops gops 支持列出当前环境下的进程信息。 在 .go 中： 123456789101112import ( \"log\" \"github.com/google/gops/agent\")// ...if err := agent.Start(); err != nil { log.Fatalln(err)}// ... 在 terminal 中： 12345$ gops # 查看进程信息$ gops stats PID # 查看状态信息$ gops stack PID # 查看堆栈信息 leaktest leaktest 将泄漏检测过程加入到自动化测试中去。 1234567891011import ( \"github.com/fortytw2/leaktest\")// ...defer leaktest.Check(t)defer leaktest.CheckTimeout(t, time.Second)defer leaktest.CheckContext(ctx, t)// ... goroutine 泄漏分类无退出的计算循环 对于没有函数调用，纯循环计算的 G，runtime 无法实行抢占； 显然，如果没有退出机制且程序常驻的话，每次启动的 goroutine 都得不到释放，就会发生 goroutine 泄漏。 12345678910111213141516171819202122package mainimport ( \"fmt\" \"runtime\" \"time\")func test() { for { fmt.Println(\"Testing...\") // 死循环无法抢占和回收 }}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} 不结束的I/O请求 对于 I/O 请求，runtime 无法实行抢占； 如果 I/O 请求一直处于等待期间，该 goroutine 则无法释放，出现泄漏。 1234567891011121314151617181920212223242526package mainimport ( \"bufio\" \"fmt\" \"os\" \"runtime\" \"time\")func test() { input := bufio.NewScanner(os.Stdin) if input.Scan() { text := input.Text() // I/O请求无法抢占和回收 fmt.Println(text) }}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} channel 引起的泄漏只发送不接收 上游生产速度远远大于下游消费速度，阻塞的 goroutine 会一直在 channel 的发送等待队列。 无缓冲 channel 没有接收就会阻塞，有缓冲 channel 缓冲满了就会阻塞。 123456789101112131415161718192021222324252627282930package mainimport ( \"fmt\" \"math/rand\" \"runtime\" \"time\")func query() int { n := rand.Intn(100) return n}func queryAll() int { ch := make(chan int) go func() { ch &lt;- query() }() go func() { ch &lt;- query() }() go func() { ch &lt;- query() }() return &lt;-ch}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 3 ，发生泄漏 }() queryAll()} 只接收不发送 下游消费速度远远大于上游生产速度，阻塞的 goroutine 会一直在 channel 的接收等待队列。 无缓冲 channel 仍然接收就会阻塞，有缓冲 channel 缓冲空了就会阻塞。 12345678910111213141516171819package mainimport ( \"fmt\" \"runtime\" \"time\")func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() ch := make(chan bool) go func() { ch &lt;- true }()} 空 channel 向 nil channel 发送和接收数据都会导致阻塞，只进行声明而不初始化 channel 容易出现该类泄漏。 12345678910111213141516171819202122package mainimport ( \"fmt\" \"runtime\" \"time\")func test() { var ch chan bool &lt;-ch // ch &lt;- data}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} 空 select select{} 永远无法响应导致协程阻塞，一般不会出现这种情况。 1234567891011121314151617181920package mainimport ( \"fmt\" \"runtime\" \"time\")func test() { select {}}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} sync 引起的泄漏Mutex 忘记解锁 有一个 goroutine 加锁忘了解锁，另一个 goroutine 竞争锁会失败，由此这个 goroutine 将一直地阻塞。 1234567891011121314151617181920212223242526272829package mainimport ( \"fmt\" \"runtime\" \"sync\" \"time\")func test() { var mutex sync.Mutex for i := 1; i &lt;= 2; i++ { go func() { mutex.Lock() fmt.Println(\"goroutine index:\", i) }() }}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} WaitGroup 计数错误 WaiteGroup 的 Add 和 Done 数量不对应将引起 Wait 的等待退出条件永远无法满足，从而阻塞协程。 1234567891011121314151617181920212223242526272829package mainimport ( \"fmt\" \"runtime\" \"sync\" \"time\")func test() { var wg sync.WaitGroup wg.Add(2) go func() { wg.Done() }() wg.Wait()}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} Cond 没发信号 Wait 方法阻塞等待条件变量满足条件，如果没有 Signal 或者 Broadcast，Wait 将会一直不能唤醒。 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( \"fmt\" \"runtime\" \"sync\" \"time\")func test() { cond := sync.NewCond(&amp;sync.Mutex{}) condition := false go func() { cond.L.Lock() condition = true cond.L.Unlock() }() cond.L.Lock() for !condition { cond.Wait() } cond.L.Unlock()}func main() { defer func() { time.Sleep(time.Second) fmt.Println(\"NumGoroutine:\", runtime.NumGoroutine()) // 输出为 2 ，发生泄漏 }() go test()} goroutine泄漏预防 对于计算循环和 I/O 请求：检查代码。 确保每个计算循环都会退出； 确保每个 I/O 请求都会关闭。 对于 channel 引起的泄漏：本质上是防止 channel 阻塞。 使用有缓冲的 channel ； 用 make 来声明并初始化 channel； 避免空的 select； 优雅地关闭 channel 等。 对于 sync 引起的泄漏：本质上是防止 sync 阻塞。 对于互斥锁，加锁解锁应该成对地出现，这时候可以利用 defer： 12345// ...mutex.Lock()// ...defer mutex.Unlock()// ... 对于信号量，Add(1) 和 Done() 搭配使用，而不是一开始就规定好任务计数： 123456// ...wg.Add(1)go func() { wg.Done() // ...}() 对于条件变量，条件改变后应发送信号，单播还是多播根据具体情况而定： 1234// ...condition = truecond.Signal() // or cond.Broadcast()// ... 参考链接 Go语言圣经 如何防止 goroutine 泄露（一） 如何防止 goroutine 泄露（二） Goroutine 泄露","link":"/2020/03/05/Golang与并发编程(3)/"},{"title":"#Fiddler# HTTP的通信监控和回放：Fiddler抓包与Socket发包","text":"利用Fiddler抓包和Socket发包，并用Curl脚本统计响应时间，主要分为以下四个部分： 工具的配置及工具的使用 截获、修改、发送数据包 统计网页和元素的响应时间 需注意事项及待改进事项 任务 部署类似Microsoft PetshopWeb应用基本实例，开发性能测试小工具能截获基于IE浏览器与Web服务器的交互的数据包，修改数据包（比如简化起见，修改要搜索的关键字），再把修改后的内容使用多线程的方式发送到服务器。统计请求每个网页上主要元素（gif,css等）需要的时间，以及请求整个网页的时间。 提示： 在获取数据包的过程中要根据HTTP请求的特点，从原始的数据包中过滤出HTTP的数据包。找到提交的“搜索的关键字”，将其替换成其它字符。 发送数据包使用Socket，可以参考网络编程的资料。 方法 截获数据包 修改数据包 发送数据包 记响应时间 手段 用Fiddler截获 用Python修改 用Socket发送 用Fiddler查看 验证 可用性 易用性 并发性 工具的配置安装工具Fiddler下载地址 导入证书 勾选解码 过滤保存手动 脚本 1234567891011121314151617if (oSession.fullUrl.Contains(\"baidu.com\")) { // for(var key in oSession.oRequest.headers) { // if('Referer' === key) { if(oSession.oRequest.headers['Referer'].indexOf(\"&amp;wd=\") != -1) { var fso; var file; fso = new ActiveXObject(\"Scripting.FileSystemObject\"); file = fso.OpenTextFile(\"E:\\\\MyPrograms\\\\fiddler_sessions\\\\Session\" + new Date().getTime() + \".txt\", 8 ,true, true); // file.writeLine(\"Request url: \" + oSession.url); file.writeLine(\"Request header:\" + \"\\n\" + oSession.oRequest.headers); // file.writeLine(\"Request body: \" + oSession.GetRequestBodyAsString()); file.writeLine(\"\\n\"); file.close(); } // } // }} 设置断点手动 命令 在左下角黑框框中输入命令 停止断点：bpu 开始断点：bpu $host 工具的使用Statistics Filters Inspectors Composer AutoResponder 截获数据包图形界面 使用图形界面或编程脚本应用过滤 点击左下角 Capturing或空白处 停止或开始截获数据包 使用Statistics查看时间，使用Inspectors查看内容 使用图形界面或编程脚本保存会话 修改数据包程序脚本对于手动保存的会话 123456789101112131415161718192021222324252627282930# 替换请求中的搜索字段def get_ref(file, cont): with open(file, encoding='utf-8') as f: lines = f.readlines() for line in lines: if 'Referer' in line: start = line.find(\"&amp;wd=\") end = line.find(\"&amp;rsv_pq=\") old_str = line[start+4:end] new_str = parse.quote(cont) line = line.replace(old_str, new_str) return line# 重新拼装需发送的报文def get_req(file, cont): msg = '' with open(file, encoding='utf-8') as f: lines = f.readlines() for line in lines: if 'GET' in line: line = 'GET ' + get_ref(file, cont)[9:-1] + ' HTTP/1.1' if 'Referer' in line: line = get_ref(file, cont) if 'Accept-Encoding' in line: continue line = line.strip('\\n') + '\\r\\n' msg += line msg = bytes(msg, encoding=\"utf8\") return msg 对于自动保存的会话 1234567891011121314151617181920212223242526272829303132# 替换请求中的搜索字段def get_ref(file, cont): with open(file, encoding='utf-16') as f: lines = f.readlines() for line in lines: if 'Referer' in line: start = line.find(\"&amp;wd=\") end = line.find(\"&amp;rsv_pq=\") old_str = line[start+4:end] new_str = parse.quote(cont) line = line.replace(old_str, new_str) return line# 重新拼装需发送的报文def get_req(file, cont): msg = '' with open(file, encoding='utf-16') as f: lines = f.readlines() for line in lines: if 'Request header:' in line: continue if 'GET' in line: line = 'GET ' + get_ref(file, cont)[9:-1] + ' HTTP/1.1' if 'Referer' in line: line = get_ref(file, cont) if 'Accept-Encoding' in line: continue line = line.strip('\\n') + '\\r\\n' msg += line msg = bytes(msg[:-4], encoding=\"utf8\") return msg 发送数据包Fiddler使用WebForms 使用图形界面或编程脚本应用过滤 使用图形界面或运行命令设置断点 在 对应报文A 的 Request WebForms内修改“搜索关键字” 点击 Break on Response 将修改后的 对应报文A 发送到Fiddler 在 对应报文B 的 Request WebForms内查看“搜索关键字” 点击 Run to Completion 将修改后的 对应报文B 发送到Server 使用Composer 保存会话Request请求头部 在记事本内修改“搜索关键字” 在Composer内发送请求报文 Socket 123456789101112131415161718192021222324252627282930if __name__ == '__main__': # 读取信息 file = input(\"file:\") cont = input(\"cont:\") # 套接字连接服务端 s = ssl.wrap_socket(socket.socket()) s.connect(('www.baidu.com', 443)) # 发送修改后的请求 s.send(get_req(file, cont)) # 缓存服务端的响应 buffer = [] while True: d = s.recv(1024) if d: buffer.append(d) else: break res = b''.join(buffer) # 客户端关闭套接字 s.close() # 保存响应 header, html = res.split(b'\\r\\n\\r\\n', 1) print(header.decode('utf-8')) with open(cont + '.html', 'wb') as f: f.write(html) 记响应时间FiddlerPyCurlUrllibRequest实例的演示 [仅使用Fiddler抓包、修改、发包](录屏链接To be continue…) [Fiddler抓包+Python修改+Socket发包](录屏链接To be continue…) 需注意事项报文格式 无论使手动还是脚本保存会话的请求报文，都需要注意每个属性是否以 \\r\\n 结尾，最后属性是否以 \\r\\n\\r\\n 结尾 遇到 HTTP 400 Bad Request 响应仔细检查报文格式是否正确 编码问题 注意保存会话的编码格式，手动保存使用编码格式 utf-8 ，脚本保存使用编码格式 utf-16 Socket发送报文和接受报文都需要二进制数据 Fiddler默认使用GZip格式压缩，在发送请求报文时为确保响应主题非乱码，应该去除 Accept-Encoding: gzip, deflate 这行属性 端口问题 Socket通信需要知道主机地址及其端口号 Fiddler Sessions或Inpectors可知主机地址及其端口号 保存的TCP报文（使用Wireshark）可知主机地址及其端口号 保存的HTTP/HTTPS报文（使用Fiddler）仅知主机地址，已知常用端口：HTTP为80/HTTPS为443 请求变化 Break on Response 和 Run to Completion 对应会话并不相同 待改进事项 优化过滤会话和替换内容脚本（正则表达式） 发送响应回浏览器（Socket向其它进程发报文） 持续化、多线程抓包、修改、发包（多线程编程）","link":"/2019/10/11/HTTP的通信监控和回放：Fiddler抓包与Socket发包/"},{"title":"#Golang# Golang与编程范式之面向对象编程","text":"介绍 Golang 中的面向对象思想实践，主要讨论以下四个部分： 类和对象 封装 继承 多态 目录 Table of Contents 简介 Golang 的起源受诸多早期编程语言的影响。类 C 让 Golang 本质上更倾向于是一门面向过程的语言，同时Golang 也借鉴了 Alef 来设计 Golang 的函数式编程特性，融合 CSP 中使用管道进行通信和控制同步的思想则很好地体现了如何面向消息编程。 虽然 Golang 不是一门传统的面向对象语言，但是 Golang 的设计却深受面向对象思想的影响。我们可以通过一种 Golang 的方式来实现面向对象的重要特性，这也是接下来将要讨论的重点。 PS：本文 just 一点自己的见解，学识有限难免有误，也希望可以抛砖引玉，欢迎大家的勘误和讨论╰(￣ω￣ｏ) 类和对象 众所周知🤫，类和对象是面向对象编程的灵魂（？类定义了一件事物的抽象特点，包含了数据的形式和对数据的操作；对象是类的实例，可以通过构造函数和析构函数来进行对生成和销毁的特殊处理。 C++ 的类和对象12345678910111213141516171819202122232425262728293031323334class Person {private: // 数据成员 string name; protected: // 数据方法 string getName() { return this-&gt;name; } void setName(string name) { this-&gt;name = name; } public: // 构造函数 Person(string name) { this-&gt;name = name; } // 析构函数 ~Person() { // ... }};int main() { Person* somebody = new Person(\"Bot\"); cout &lt;&lt; somebody-&gt;getName() &lt;&lt; endl; // Output: Bot somebody-&gt;setName(\"Exp\"); cout &lt;&lt; somebody-&gt;getName() &lt;&lt; endl; // Output: Exp return 0;} Golang的“类和对象”1234567891011121314151617181920212223242526272829type Person struct { // 数据成员 name string}// 数据方法func (this *Person) GetName() string { return p.name}func (this *Person) SetName(name string) { p.name = name}// 构造函数func NewPerson(string name) *Person { return &amp;Person{ name: name, }}// 析构函数// 由于 Golang 采用垃圾回收机制，一般不需要显式写析构函数func main() { somebody := NewPerson(\"Bot\") fmt.Println(somebody.getName()) // Output: Bot somebody.SetName(\"Exp\") fmt.Println(somebody.getName()) // Output: Exp} 区别联系耦合程度 C++ 的类是面向 class 而言的，数据成员和数据方法都必须在 class 内修改，可见耦合程度较高。 Golang 的“类”是面向 type 而言的，数据成员在 struct 内修改，数据方法则是可以在任意处增删 (recv *receiver_type) 对应的方法，可见耦合程度较低。 【PS：这里 type 的外延比 class 要广，type 除包括自定义类型外还支持内置类型的别名】 this 指针 C++ 对象的 this 指针常常是隐式的，每一个数据方法实际上都隐式传入了一个指向该对象的 this 指针： 123void setName([Person* this], string name) { this-&gt;name = name;} Golang “对象”的 this 指针必须是显式的，不难看出 this 指针是连接 Golang 中类型和方法的关键桥梁： 123func (this *Person) setName(string name) { this.name = name} 构造与析构 C++ 的构造函数和析构函数是比较容易理解的，构造函数在对象创建时被自动调用，析构函数在对象销毁时被自动调用。由于 C++ 无垃圾回收机制，对象的生命周期和作用域紧密相关。 Golang 严格上来说没有构造函数和析构函数的说法，可以通过用来专门做初始化的函数来模拟构造函数，而defer 和 finalizer 有类似析构的意味，但本质还是很不同的。由于 Golang 有垃圾回收机制，对象的生命周期取决于何时被 GC 进程回收，一般而言当变量不再被引用就会被垃圾回收掉。 封装 封装 aka 信息隐藏，其实包含了两层意思：一是调用方无须关心实现细节，二是调用方无法更改实现细节。封装在编程语言中一般体现在访问权限中。 Java 的封装 以经典的 OO 语言 Java 为例，由于 Java 同时存在类和包的概念，其访问权限需要考虑到两个维度，相对而言比较复杂。其中，Java 的访问权限通过关键字定义： public：公共可见，所有类可见 protected：继承可见，必须为继承关系，允许跨包 [default]：包内可见，不要求继承关系，仅限同包 private：私有可见，仅本类可见 Golang 的封装 而在 Golang 中没有所谓的类和对象概念（或者说可以用很 Golang 的方式类似实现），但引入了包管理机制，Golang 中只有简化的两层访问权限。其中，Golang 的访问权限通过标识符大小写定义： 标识符首字母大写：包外可见，所有的包均可见 标识符首字母小写：包内可见，本包文件均可见 一些说明 Golang 中的 标识符首字母大写 类似于 Java 中的 public Golang 中的 标识符首字母小写 类似于 Java 中的 [default] 继承 继承涉及三方面的内容：一是子类可以使用父类的属性和方法，避免重复编码；二是子类可以覆盖父类的属性和方法，是实现多态的必要条件之一；三是子类可以追加属于自己的属性和方法，完成子类的定制功能。 C++ 的继承123456789101112131415161718192021222324252627282930313233343536373839class Parent {public: // ... virtual void parentFunc() { // ... } virtual void parentFunc(params) { // ... } virtual void overrideFunc() { // Parent class content }}class Child: public Parent {public: // ... virtual void overrideFunc() { // Child class content } virtual void childFunc() { // ... }};int main() { Child* child = new Child(); child-&gt;parentFunc(); // 使用父类方法 child-&gt;overrideFunc(); // 使用已覆盖的子类方法 child-&gt;Parent::overrideFunc(); // 使用未覆盖的父类方法 child-&gt;childFunc(); // 使用子类方法 return 0;} Golang 的继承1234567891011121314151617181920212223242526272829303132type Parent struct { // ...}func (p *Parent) ParentFunc() { // ...}func (p *Parent) OverrideFunc() { // Parent class content}type Child struct { parent Parent // ...}func (c *Child) OverrideFunc() { // Child class content}func (c *Child) ChildFunc() { // ...}func main() { child := &amp;Child{} child.ParentFunc() // 使用父类方法 child.OverrideFunc() // 使用已覆盖的子类方法 child.parent.OverrideFunc() // 使用未覆盖的父类方法 child.ChildFunc() // 使用子类方法} 一些说明 C++ 的继承更像是链式继承，从父类到子类进行构造，从子类到父类进行访问 Golang 的继承更像是组合继承，子类内嵌一个或多个父类 从 Golang 的继承机制容易看出它支持多继承，一些编程语言（如 Java）仅支持单继承 多态 多态指同一操作作用于不同的对象，可以有不同的解释，产生不同的执行结果。当我们讨论多态时，我们常常会讨论重载以及重写和动态绑定。 语言基础接口 类型绑定方法集，接口定义方法集。如果类型绑定的方法集和接口定义的方法集重合，那么类型实现了接口。 类型内定义了有什么属性，接口内定义了有什么操作，两者产生关联的关键是方法是否都被实现。 接口是隐式实现的，不需要显式声明；接口是一种特殊的类型，它可以被赋值成实例的指针或引用。 基于以上事实，我们可以知道： 不同的接口可以完成不同的组合操作； 多个类型可以实现同个接口，一个类型可以实现多个接口； 不同的类型完成不同的组合操作，看起来却是同一个接口，这就是多态！ 断言 虽然我们提供对外提供了统一接口调用的方案，但是对内我们到底如何从接口出发辨别纷繁的类型呢？给定一个类型我们又该如何确定它是否实现了某个接口？ 类型断言和类型选择：给定接口确定类型 1234567891011121314// 类型断言if _, ok := varI.(T); ok {// ...}// 类型选择switch t := varI.(type) {case T:// ...case nil:// ...default:// ...} 接口断言：给定类型确定接口 1234// 接口断言if _, ok := varT.(I); ok {// ...} Golang 的多态重载 重载是指根据不同的方法签名调用不同的函数实现。 Golang 的设计思想中是不允许任何形式的重载的，这是为了强化显式化的风格。 【PS：不同类型的接收器绑定的同名方法，严格来说不算重载】 尽管 Golang 本身不提供重载的机制，我们还是可以借助接口来实现类似的功能。 12345678910111213141516171819202122func Speak(persons ...interface{}) { for _, person := range persons { switch t := person.(type) { case Chinese: // Speak Chinese case American: // Speak English case nil: // Error handler default: // Default handler } }}func main() { chinese := Chinese{} american := american{} Speak(chinese) // Speak Chinese Speak(american) // Speak English Speak(chinese, american) // chinese Speak Chinese, american Speak English} 重写和动态绑定 重写和动态绑定是为了允许将子类类型的指针赋值给父类类型的指针，在运行时可以通过指向父类的指针来调用实现子类中的方法。 既然Golang中不存在严格的类和对象，重写和动态绑定的理论其实并不太适合 Golang，我们只需要关心怎么将利用一个接口访问可以定位到具体的类型就可以了。 Golang 实现了编译时静态接口判断（类型是否实现接口），运行时动态类型选择（到底是哪种类型）。 1234567891011121314151617181920212223242526272829303132type Animal interface { move() // ...}type Bird struct { // ...}func (b *Bird) move() { // fly}type Pig struct { // ...}func (p *Pig) move() { // walk}func main() { var animal Animal bird := Bird{} pig := Pig{} animal = bird animal.move() // fly animal = pig animal.move() // walk} 参考链接 《Go语言圣经》 《Go入门指南》 致谢 感谢王同学坚持不懈的“八点钟检查”以及一点都不嫌弃的“康康博客”，让我得以在快要写不下去的时候还坚持着做一些有意义的复读，XOXO。","link":"/2020/03/01/Golang与编程范式(1)/"},{"title":"#Docker# LinuxOne上的Docker初体验","text":"在LinuxOne上利用Docker部署应用与服务，主要分为以下五个部分： 环境准备 Environment Docker原理 Theory Docker使用 Usage Docker实战 Practice 注意事项 Notices 目录 Table of Contents 环境准备 Environment申请Github账号并配置好本地Git 廖雪峰Git教程 申请IBM ID账号并开通开发者账号 该步骤主要提供接口权限 Register IBM ID （统一邮箱） Create an API Developer Portal account （统一邮箱） Apps Create new App Configure the App: Title: $TITLE Sumbit Client ID Client Secret API Products Use banking API Subscribe Default Plan Select Previous App Subscribe 申请IBM LinuxOne账号 该步骤主要提供部署环境 Virtual Machine Login Virtual Services Manage Instances Create Instances Configure the Instance Type: General purpose VM Instance Name: $INSTANCE_NAME Instance Description: $INSTANCE_DESCRITION Image: RHEL7.6 SSH Key Pairs: Create → Save → Select → Create Check the Instance Status: Active Linux User: linux1 IP Address: 148.100.xxx.xxx Private Cloud Login Catalog openmplbank Configure Input Release name Select Target Namespace Install View Helm Release Deployment AVAILABLE = 1 Launch 安装Node.js环境 安装Node.js: Download | Node.js 检查是否安装成功: 12$ node -v$ npm -v 安装SSH登录工具 Windows：可选PuTTY或Xshell或WSL Linux：ssh -i /path/to/key/keyname.pem linuxusername@serveripaddress Docker原理 Theory工作流程 名词辨析 概念 含义 Docker 镜像(Images) Docker镜像是用于创建Docker容器的模板。 Docker 容器(Container) Docker容器是独立运行的一个或一组应用。 Docker 客户端(Client) Docker客户端通过命令行或者其他工具使用Docker API，与Docker的守护进程通信。 Docker 主机(Host) Docker主机是一个物理或者虚拟的机器用于执行Docker守护进程和容器。 Docker使用 Usage安装 安装docker 123456789101112# 下载Docker归档包wget ftp://ftp.unicamp.br/pub/linuxpatch/s390x/redhat/rhel7.3/docker-17.05.0-ce-rhel7.3-20170523.tar.gz# 解压Docker归档包tar -xzvf docker-17.05.0-ce-rhel7.3-20170523.tar.gz# 迁移Docker归档包# !!! 这里直接cp到/usr/bin就好，因为/usr/local/bin不在PATH环境变量里 !!!cp docker-17.05.0-ce-rhel7.3-20170523/docker* /usr/bin/ 安装docker-compose 12345678910111213141516171819202122232425262728293031# 查看python-setuptoolsyum info python-setuptools# 安装python-setuptoolsyum install -y python-setuptools# 安装pipeasy_install pip# 网速过慢的话先禁用掉 IPv6echo 1 &gt; /proc/sys/net/ipv6/conf/all/disable_ipv6# 升级backports.ssl_match_hostnamepip install backports.ssl_match_hostname --upgrade --ignore-installed# 先安装依赖，不然会报错yum install python-devel libffi-devel# 安装docker-composepip install docker-compose==1.13.0# 查看docker-compose安装情况和版本信息docker-compose version 命令 后台启动daemon进程 1234# -g 设置Docker Daemon运行时的根目录# &amp; 放在命令后面表示设置此进程为后台进程docker daemon -g /local/docker/lib &amp; 命令查看docker信息 1234567# 查看当前机器docker版本老旧docker version# 检查后台有无docker进程运行ps aux | grep docker docker镜像处理 1234567891011# 查看所有镜像docker images# 拉取远程镜像docker image pull repository:tag# 构建本地镜像docker build -t \"repository:tag\" ./ docker容器处理 1234567891011# 查看所有容器docker ps# 创建运行容器docker run image# 停止运行容器docker stop container docker服务处理 1234567891011# 查看所有服务docker-compose ps# 创建运行服务docker-compose up# 停止运行服务docker-compose down docker build 123# -t 在新容器内指定一个伪终端或终端docker build -t \"repository:tag\" ./ docker run 12345# -d 开启daemon模式# -i 允许你对容器内的标准输入 (STDIN) 进行交互# -p 指定端口映射规则docker run -d -i -p ipadress1:port1/protocal:ipadress2:port2/protocal repository:tag docker-compose up 1234# -d 开启daemon模式# 端口映射和镜像来源都写在了.yml配置文件docker-compose up -d docker exec 1234# -i 允许你对容器内的标准输入 (STDIN) 进行交互# -t 在新容器内指定一个伪终端或终端docker exec –it container bash Docker实战 Practice切换权限和路径，配置用户习惯123456789101112131415# 切为根用户，否则没有权限sudo su# 切到家目录，否则难找文件cd ~# RHEL 7.6已经自带安装了VIM 7.4，启动命令是vi，习惯用vim命令的同学可以先设置一下别名[当前生效]alias vim='vi'# RHEL 7.6已经自带安装了VIM 7.4，启动命令是vi，习惯用vim命令的同学可以先设置一下别名[永久生效]# !!! 可以将alias vim='vi'加到~/.bashrc中 !!!source ~/.bashrc 安装并运行 WebSphere Liberty（练习使用docker run）123456789# 手动拉取websphere-liberty镜像到本地docker image pull s390x/websphere-liberty:webProfile7# 后台运行容器，并指定端口映射规则docker run -d -p 80:9080 -p 443:9443 s390x/websphere-liberty:webProfile7# 浏览器访问http://[LinuxOne Host IP]，即可看到WebSphere Liberty的界面 安装并运行 WordPress（练习使用docker-compose up）12345678910111213141516171819202122232425262728293031323334353637383940# 创建docker-compose.ymlvim docker-compose.yml# 编辑docker-compose.ymlversion: '2'services: wordpress: image: s390x/wordpress ports: - 8080:80 # 将本地 8080 端口映射到容器的 80 端口 environment: WORDPRESS_DB_PASSWORD: example mysql: image: brunswickheads/mariadb-5.5-s390x environment: MYSQL_ROOT_PASSWORD: example:wq# 查看docker-compose.ymlcat docker-compose.yml# 创建wordpress目录方便整理mkdir wordpressmv docker-compose.yml wordpress/cd wordpress/# 根据docker-compose.yml中定义的服务启动容器docker-compose up -d# 创建完成后，查看相关容器的状态docker-compose ps# 浏览器访问http://[Your LinuxONE IP Address]:8080，即可看到 WordPress 的页面 安装并运行 Todo App（熟悉MEAN Stack + Docker架构）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# 为方便管理文件，切换到家目录cd ~# 从Github拉取源码到本地使用git clone https://github.com/IBM/Cloud-Native-Workloads-on-LinuxONE# 迁移源码文件夹到家目录cp -r Cloud-Native-Workloads-on-LinuxONE/files/mean-docker ./# 安装显示目录树的插件包yum install -y tree# 显示mean-docker的目录树tree mean-dockermean-docker├── docker-compose.yml # docker-compose 配置文件├── express-server│ ├── app│ │ ├── models│ │ │ └── todo.js│ │ └── routes.js│ ├── config│ │ └── database.js│ ├── Dockerfile # docker image 生成文件│ ├── license│ ├── package.json│ ├── public│ │ ├── index.html # 前端文件│ │ └── js│ │ ├── controllers│ │ │ └── main.js # 后端文件│ │ ├── core.js│ │ └── services│ │ └── todos.js # 数据库文件│ ├── README.md│ └── server.js└── README.md # 说明文档8 directories, 14 files# 修改Angular.js成国内镜像源vim mean-docker/express-server/public/index.htmlsrc=\"//cdn.bootcss.com/angular.js/1.2.16/angular.min.js\"# 查看Dockerfile的内容cd express-server/lsvim Dockerfile# 编辑Dockerfile的内容# Expose the port the app runs inEXPOSE 8081......# Express listening portENV PORT 8081:wq# 重新构建镜像cd mean-dockerdocker-compose down # 停止正在运行的容器docker-compose build # 先重新构建镜像docker-compose up # 再基于新镜像重新启动容器# 查看docker-compose.yml的内容cd mean-docker/lsvim docker-compose.yml# 编辑docker-compose.yml的内容# 因为之前本地的8080端口被 WordPress 占用了，所以这里我们使用8081端口......ports:- \"8081:8081\" # 本地 8081 端口映射到 express 容器的 8081 端口......:wq# 启动指定服务docker-compose up -d# 使用docker-compose ps命令查看启动的容器docker-compose ps# 浏览器访问http://[ip of machine]:8081，即可看到你的 TODO-List App Todo App前端插入数据、后端处理数据、数据库查数据（熟悉MEAN Stack + Docker前后端数据库交互）1234567891011121314151617181920212223242526272829......# 在运行的容器中执行命令docker exec –it meandocker_database_1 bash# 进入MongoDB&gt; mongo# 查看数据库&gt; show dbs# 指定数据库&gt; use docker-mean# 枚举数据表&gt; show tables# 查看元祖集&gt; db.todos.find()# 指定元祖项&gt; db.todos.find({\"key\": \"value\"}) 本地部署金融微服务（熟悉Localhost → Micro-services模式）12345678910111213141516171819202122232425# Fork ICp-banking-microservices 到自己账号下，将你Fork的项目git clone至本地# Github配置过SSHgit clone git@github.com:LotteWong/ICp-banking-microservices.git# Github未配置SSHgit clone https://github.com/YOUR_USERNAME/ICp-banking-microservices# 在banking-application/public/js/bankingAPI.js中填入你的Client ID和Client Secret# 进入ICp-banking-microservices/banking-application目录，安装npm依赖npm install# 如果出现npm代理设置错误，重新设置代理即可npm config set registry \"http://registry.npmjs.org/\"# 进入ICp-banking-microservices/banking-application目录，启动应用node app.js# 浏览器访问http://localhost:3000，即可访问应用# 随便选择一个customer ID测试，若有JSON格式的数据返回，则说明API可用。如果出错可自排查，可能是ID和Secret不匹配（前往开发者页面的应用程序页面中验证ID和Secret）或者浏览器不支持网速较慢之类（更换浏览器更换网络源） 远程部署金融微服务（熟悉Docker → Micro-services模式）1234567891011121314151617181920212223242526272829303132333435363738# 在非 LinuxOne 的本机将项目推送至 Github 远程仓库# !!! 实际上不应该把Client ID和Client Secret这种密钥类型的数据推到 Github 上，这里为了方便实验暂时这么做，以后切勿模仿。 !!!git add public/js/bankingAPI.jsgit commit -m \"Update of bankingAPI.js\"git push origin master# 先登录你的 LinuxONE 主机实例，为方便管理文件，切换到家目录cd ~# 将你 Fork 后又更新的代码拉取到本地# Github配置过SSHgit clone git@github.com:LotteWong/ICp-banking-microservices.git# Github未配置SSHgit clone https://github.com/YOUR_USERNAME/ICp-banking-microservices# 构建 Docker 镜像docker build -t \"respository:tag\" ./# 查看 Docker 镜像docker images# 启动 Docker 容器docker run -p 3000:3000 respository:tag# 查看 Docker 容器docker ps# 浏览器访问http://[LinuxOne Host IP]:3000，即可访问应用# 随便选择一个customer ID测试，若有JSON格式的数据返回，则说明API可用。如果出错可自排查，可能是ID和Secret不匹配（前往开发者页面的应用程序页面中验证ID和Secret）或者浏览器不支持网速较慢之类（更换浏览器更换网络源） 云端部署金融微服务（熟悉Cloud → Micro-services模式）123# 到 ICP 中部署好的应用，点击启动，浏览器会自动跳转到分配的端口# 之后就和此前的实验一样了，只不过你的应用是部署在 ICP 上，由 Kubernetes 自动维护可用的 Pod 数量 注意事项 Notices 端口映射就是将主机的IP地址的一个端口映射到局域网中一台机器，当用户访问这个IP的这个端口时，服务器自动将请求映射到对应局域网分机。 .pem为通用证书格式，ppk为PuTTY下面的专有格式。两者都为SSH Key Pairs格式，内含公钥和密钥。 镜像是类，容器是对象，服务是对象集。Dockerfile用于构建镜像；docker-compose.yml用于组织镜像；docker run用于启动容器；docker-compose up用于启动服务。 使用Docker需要非常注意卷的管理，如果采用默认匿名的方式而不指定卷的位置，服务器的容量很快就会被每次重新生成的同一镜像给爆掉。 MEAN Stack包括MongoDB（数据库）、Express.js（路由）、AngularJS（前端）和Node.js（后端）。本次实验最终项目友链 👉 SCUT Online Bank Application。","link":"/2019/06/18/LinuxOne上的Docker实践/"},{"title":"#WSL# WSL从入门到...(2) Dive into WSL 1","text":"对 WSL 1 的一些实现细节进行补充说明，主要分为以下五个部分： 前情提要 背景 架构与功能 总结 参考链接 目录 Table of Contents 前情提要 前面已经简要介绍了 WSL 1 和 WSL 2 的区别，本节将聚焦于 WSL 1的实现细节。点开官方博客开始收获惊(da)喜(keng)，才疏学浅写错也不要打我 (预先感谢各位勘误 逃 【更多信息 👉 WSL从入门到…(1) WSL 1 vs WSL 2】 背景 Early subsystems were implemented as user mode modules that issued appropriate NT system calls based on the API they presented to applications for that subsystem. All applications were PE/COFF executables, a set of libraries and services to implement the subsystem API and NTDLL to perform the NT system call. When a user mode application got launched, the loader invoked the right subsystem to satisfy the application dependencies based on the executable header. 早期的子系统采用的方法是，将子系统视为上层的一系列进程组，通过 NTDLL 提供的 API 实现用户模式和内核模式通信，其中 loader 对 application 和 subsystem 进行管理。这里运行的仍然是 Win32 binaries，需要移植和维护。 Later versions of subsystems replaced the POSIX layer to provide the Subsystem for Unix-based Applications (SUA). The primary role of SUA was to encourage applications to get ported to Windows without significant rewrites. This was achieved by implementing the POSIX user mode APIs using NT constructs. 后来的子系统采用的方法是，在 POSIX 层做优化，移植而不是重写。这里运行的仍然是 Win32 binaries，需要移植和维护。 WSL is a collection of components that enables native Linux ELF64 binaries to run on Windows. It contains both user mode and kernel mode components. It is primarily comprised of: User mode session manager service that handles the Linux instance life cycle Pico provider drivers (lxss.sys, lxcore.sys) that emulate a Linux kernel by translating Linux syscalls Pico processes that host the unmodified user mode Linux (e.g. /bin/bash) WSL 采用的方法是，构造一整套包含用户模式和内核模式组件的系统，其主要由用户模式会话管理服务（User mode session manager service）、Pico 驱动（Pico provider drivers）和 Pico 进程 （Pico processes）三个部分组成。这里运行的仍然是 Linux binaries，无需移植和维护。 架构 工作流大概是：Windows 的 Bash 键入指令，交由 LXSS Manager Service 启动对应的 Linux 实例并进入对应的 Pico 进程，Linux 的 Bash 通过中间层的驱动器与 Windows Kernel 进行翻译交流（“The lxss.sys and lxcore.sys drivers translate the Linux system calls into NT APIs and emulate the Linux kernel.”）。 LXSS Manager Service LXSS Manager Service 负责 Windows 的 Bash（Win32 Process）和 Linux 的 Bash（Pico Process）之间的通信，主要在初始时工作。作用范围包括但不局限于：同步 Linux 实例的安装和卸载、每次只允许一个进程启动 Linux Binary 并在 pending 时阻塞后续启动进程等等。 Pico Drivers Pico Drivers 负责 Linux Instance（User Mode）和 Windows Kernel（Kernel Mode）之间的通信，主要在运行时工作。作用范围包括但不局限于：翻译 Linux system calls 为 Windows NT APIs 可以理解的形式，模拟 Linux 内核并对 Windows 内核进行操作等等。 Pico Processes 将可执行的 ELF binaries 加载进到 Pico Processes 的地址空间，并在 Linux 层上运行。其中 Linux 实例是一个特殊的为 Pico Processes 服务的数据结构，可以包含并追踪所有的 Linux 进程、线程和运行状态。它在 Win32 Process 首次启动 Linux Binary 时创建，在 Win32 Process 最后的客户端关闭连接时被销毁。从整体上看，整个 WSL 1 只有一个 Linux 实例，它隔离开了本机原有的 Windows 和所有新建的 Linux ；从内部来看，Linux 实例内的每个 Pico Process 都被单独隔离，这点和容器很类似。 功能 由于 Windows Kernel 和 Linux Kernel 基本上不兼容，需要额外处理很多中间转换，一般包括系统调用、文件系统、权限管理和网络配置等，下面介绍最基本和最重要的两个方面： System Calls syscall 是内核提供的一项服务，可以在用户模式下调用。Windows Kernel 和 Linux Kernel 都暴露了非常多的 syscall，但两者对此的设计模式并不同导致不兼容。 解决这种冲突的方法是引入 Pico Drivers（lxss.sys and lxcore.sys）。当一个 Linux Kernel syscall 被调用，该请求将被转发给 lxcore.sys，lxcore.sys 将 Linux Kernel syscall 翻译成等价的 Windows Kernel syscall，最后传到 Windows Kernel。特别地，如果在两种内核之间有某个 syscall 不存在映射关系（亦即不能互相翻译），lxss.sys 还被要求处理这种异常并提供相应的服务。 以 Linux 的 fork() 为例： As an example, the Linux fork() syscall has no direct equivalent call documented for Windows. When a fork system call is made to the Windows Subsystem for Linux, lxcore.sys does some of the initial work to prepare for copying the process. It then calls internal Windows NT kernel APIs to create the process with the correct semantics, and completes copying additional data for the new process. 以 Linux 的 chmod 为例： Linux Instance 产生附加 metadata，只由 Linux 文件系统能理解， Windows 文件系统并不能理解，但是 Windows Kernel 仍会接收该 metadata。但是 NTFS 对这个 metadata 无动于衷，而是 lxss.sys 处理该 metadata，最终反映到 ext4 中。由此可见，WSL 1 非常大的工作量都要花在应对不兼容的指令集。 PS: 尽管 Linux 的内核更新得非常快，用户模式的接口却是相对固定的，所以可以认为“WSL 1 abstracts the Linux kernel via their interface” File System 由于 Windows 和 Linux 的文件系统也不相同（Windows 的文件系统是 NTFS，Linux 的文件系统是 ext4），不能直接互相操作。WSL 的文件系统设计需要满足两点： 完整支持 Linux 文件系统 可访问和操作 Windows 中的磁盘和文件 为实现以上的目标 WSL 引入了两套文件系统（VolFs and DriveFs）。 VolFs 文件系统主要提供了 Linux 文件系统特性的支持，比如 Linux 文件目录（/etc, /bin, /usr, etc.）、权限管理和符号链接等等。DriveDs 文件系统主要用于与 Windows 做交互，比如 Windows 文件目录（/mnt/c, /mnt/d, etc.）、启动 Windows 的可执行文件等等。 PS: 需要注意的是，两套文件系统之间是如何进行交互的并未在原博客详细讨论，感兴趣的小伙伴可自行阅读续篇 WSL File System Support 总结 简单的理解：WSL 1 在 Windows Kernel 之上创建 Linux Instance，Win32 Process 通过 LXSS Manager Service 管理 Pico Process，用户模式的 Linux Instance 和内核模式的 Windows Kernel 之间通过 Pico Drivers 交流，依靠中间层驱动器翻译可以解决 System Calls 不兼容的问题，设计两套文件系统能够满足同时使用 Windows 和 Linux 的需要。 参考链接 Windows Subsystem for Linux Overview Project Drawbridge","link":"/2019/12/13/WSL从入门到...(2)/"},{"title":"#WSL# WSL从入门到...(4) Quick Start on WSL","text":"安装、配置并使用 WSL ，主要分为以下五个部分： 前情提要 安装发行版本 编写配置脚本 使用相关命令 参考链接 目录 Table of Contents 前情提要 终于结束漫长的听力翻译和阅读理解，开始真正搞机（期待地搓手手.gif。本文将解锁 WSL 1 初体验（发现 Windows build 版本好像快落后了一个世纪，WSL 2 装不了惹。 安装发行版本 配置相关： Windows 10 家庭中文版 1903 64 位操作系统，基于 x64 的处理器 WSL 1 Ubuntu 16.04 LTS Alpine WSL Step 1: 开启支持 WSL 选项 方法一：控制面板设置 “控制面板” -&gt; “程序” -&gt; “启用或关闭 Windows 功能” -&gt; “适用于 Linux 的 Windows 子系统” 重启电脑 方法二：输入命令设置 “Windows PowerShell（以管理员身份运行）” -&gt; Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 重启电脑 Step 2: 安装 Linux 发行版本 方法一：Microsoft Store 安装 打开应用商店 选择发行版本 Ubuntu 16.04 LTS Ubuntu 18.04 LTS OpenSUSE Leap 15 OpenSUSE Leap 42 SUSE Linux Enterprise Server 12 SUSE Linux Enterprise Server 15 Kali Linux Debian GNU/Linux Fedora Remix for WSL Pengwin Pengwin Enterprise Alpine WSL 安装发行版本 方法二：Command-Line/Script 安装 Manually download Windows Subsystem for Linux distro packages Step 3: 配置 Linux 发行版本 启动已安装好的 Linux 发行版本 点击启动： 菜单栏单击运行发行版本 磁贴板单击运行发行版本 命令启动： bash.exe ：默认目录为 Windows 用户目录 distro.exe：默认目录为 Linux 用户目录 wsl.exe：允许 Windows 和 Linux 的命令混用 等待 Linux 发行版本解压缩和初始化 创建 Linux 下的新用户及其密码 管理员用户之一 每次进入的默认用户 与 Windows 用户名无关 定期更新 Linux 下的 Package sudo apt update &amp;&amp; sudo apt upgrade PS: 常见报错解决页 👉 WSL troubleshooting page 编写配置脚本 WSL 支持使用 wsl.conf 来初始化自动挂载和网络配置两大功能。wsl.conf 位于 /etc目录，如果文件已存在，WSL 会自动读取适配；如果文件不存在，可以自行在目录内新建；如果文件出错了，WSL 会忽略配置文件。 自动挂载Section Label: [automount] key value default notes enabled boolean true true causes fixed drives (i.e C:/ or D:/) to be automatically mounted with DrvFs under /mnt. false means drives won’t be mounted automatically, but you could still mount them manually or via fstab. mountFsTab boolean true true sets /etc/fstab to be processed on WSL start. /etc/fstab is a file where you can declare other filesystems, like an SMB share. Thus, you can mount these filesystems automatically in WSL on start up. root String /mnt/ Sets the directory where fixed drives will be automatically mounted. For example, if you have a directory in WSL at /windir/and you specify that as the root, you would expect to see your fixed drives mounted at /windir/c options comma-separated list of values empty string This value is appended to the default DrvFs mount options string. Only DrvFs-specific options can be specified. Options that the mount binary would normally parse into a flag are not supported. If you want to explicitly specify those options, you must include every drive for which you want to do so in /etc/fstab. 网络配置Section label: [network] key value default notes generateHosts boolean true true sets WSL to generate /etc/hosts. The hosts file contains a static map of hostnames corresponding IP address. generateResolvConf boolean true true set WSL to generate /etc/resolv.conf. The resolv.conf contains a DNS list that are capable of resolving a given hostname to its IP address. 交互操作Section label: [interop] These options are available in Insider Build 17713 and later. key value default notes enabled boolean true Setting this key will determine whether WSL will support launching Windows processes. appendWindowsPath boolean true Setting this key will determine whether WSL will add Windows path elements to the $PATH environment variable. 具体示例1234567891011# Enable extra metadata options by default[automount]enabled = trueroot = /windir/options = \"metadata,umask=22,fmask=11\"mountFsTab = false# Enable DNS – even though these are turned on by default, we’ll specify here just to be explicit.[network]generateHosts = truegenerateResolvConf = true 使用相关命令查看版本列表 wsl -l, wsl --list：可用的 Linux 发行版 wsl --list --all： 未可用和已可用的 Linux 发行版 wsl --list --running：运行的 Linux 发行版 设置默认版本 wsl -s &lt;DistributionName&gt;, wsl --setdefault &lt;DistributionName&gt; 重新安装版本 wsl --unregister &lt;DistributionName&gt; 重复“安装发行版本”的“Step 3: 配置 Linux 发行版本” 指定参数登录 wsl -d, wsl --distribution：指定版本登录 wsl -u, wsl --user：指定用户登录 交互操作选择 $ echo 0 &gt; /proc/sys/fs/binfmt_misc/WSLInterop：停用交互操作 $ echo 1 &gt; /proc/sys/fs/binfmt_misc/WSLInterop：开启交互操作 Windows命令行运行Linux工具 wsl &lt;LinuxCommand&gt; 12345C:\\temp&gt; wsl ls -la | findstr \"foo\"-rwxrwxrwx 1 root root 14 Sep 27 14:26 foo.batC:\\temp&gt; dir | wsl grep foo09/27/2016 02:26 PM 14 foo.bat Linux命令行运行Windows工具 &lt;WindowsCommand&gt; 123456$ cmd.exe /C dir&lt;- contents of C:\\ -&gt;$ PING.EXE www.microsoft.comPinging e1863.dspb.akamaiedge.net [2600:1409:a:5a2::747] with 32 bytes of data:Reply from 2600:1409:a:5a2::747: time=2ms PS: 以上适用于 “Windows 10 Version 1903 and later“, “Versions Earlier than Windows 10 Version 1903 “的对应目录请查看文末的参考链接。Windows Insiders Builds 17063 起支持 Windows 和 Linux 共享环境变量；Fall Creators Update 起 Windows Path 将加入 Linux $PATH 。 参考链接 Windows Subsystem for Linux Documentation","link":"/2019/12/15/WSL从入门到...(4)/"},{"title":"#Others# 从零到壹：GitHub Pages + Hexo = Blog","text":"利用GitHub Pages+Hexo打造一个个人博客，主要分为以下五个部分： 环境准备 Environment 文件配置 Configuration 个性化 Customization 博客写作 Writing 双备份 Backup 环境准备 Environment安装Git + Github 安装Git部署插件: 1$ npm install hexo-deployer-git --save 安装Node.js 安装Node.js: Download | Node.js 检查是否安装成功: 12$ node -v$ npm -v 安装Hexo 安装Hexo: 1$ npm install -g hexo-cli 检查是否安装成功: 1$ hexo -v 初始化: 1$ hexo init blog 文件配置 Configuration本地运行123$ hexo clean # 删除缓存$ hexo g # 生成Hexo页面$ hexo s # 本地部署Hexo页面 远程运行123$ hexo clean # 删除缓存$ hexo g # 生成Hexo页面$ hexo d # 远程部署Hexo页面 基本配置/_config.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: LotteWong # 个人博客显示名称subtitle: 在代码符号表象中避难。 # 个人博客副标题description: # 搜索引擎描述信息keywords: # 搜索引擎关键词author: LotteWong # 网站作者avatar: ./themes/icarus/source/images/favicon.ico # 网站头像language: en # 网站语言timezone: Asia/HongKong # 网站时区# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/plugins: # 设置个人博客插件theme: icarus # 设置个人博客主题# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git # 部署类型 repo: git@github.com:LotteWong/lottewong.github.io.git # 部署仓库 branch: master # 部署分支 个性化 Customization/themes/icarus/_config.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234# Version of the Icarus theme that is currently usedversion: 2.3.0# Path or URL to the website's iconfavicon: /images/favicon.ico# Path or URL to RSS atom.xmlrss: # Path or URL to the website's logo to be shown on the left of the navigation bar or footerlogo: /images/logo.png# Open Graph metadata# https://hexo.io/docs/helpers.html#open-graphopen_graph: # Facebook App ID # fb_app_id: # Facebook Admin ID # fb_admins: # Twitter ID # twitter_id: # Twitter site # twitter_site: # Google+ profile link # google_plus: # Navigation bar link settingsnavbar: # Navigation bar menu links menu: Home: / Archives: /archives Categories: /categories Tags: /tags About: /about # Navigation bar links to be shown on the right # links: # Download on GitHub: # icon: fab fa-github # url: 'https://github.com/LotteWong'# Footer section link settingsfooter: # Links to be shown on the right of the footer section links: Github: icon: fab fa-github url: 'https://github.com/LotteWong' RSS: icon: fas fa-rss url: 'https://www.zhihu.com/people/lai-xiu-ping'# Article display settingsarticle: # Code highlight theme # https://github.com/highlightjs/highlight.js/tree/master/src/styles highlight: atom-one-light # Whether to show article thumbnail images thumbnail: true # Whether to show estimate article reading time readtime: true# Search plugin settings# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Searchsearch: # Name of the search plugin type: insight# Comment plugin settings# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Commentcomment: # Name of the comment plugin type: # Donation entries# https://ppoffice.github.io/hexo-theme-icarus/categories/Donation/donate: - # Donation entry name type: alipay # Qrcode image URL qrcode: '/images/alipay.png' - # Donation entry name type: wechat # Qrcode image URL qrcode: '/images/wechat.png' - # Donation entry name type: paypal # Paypal business ID or email address business: 'SuperGsama@outlook.com' # Currency code currency_code: USD - # Donation entry name # type: patreon # URL to the Patreon page # url: ''# Share plugin settings# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Shareshare: # Share plugin name type: # Sidebar settings.# Please be noted that a sidebar is only visible when it has at least one widgetsidebar: # left sidebar settings left: # Whether the left sidebar is sticky when page scrolls # https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/make-a-sidebar-sticky-when-page-scrolls/ sticky: false # right sidebar settings right: # Whether the right sidebar is sticky when page scrolls # https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/make-a-sidebar-sticky-when-page-scrolls/ sticky: false# Sidebar widget settings# https://ppoffice.github.io/hexo-theme-icarus/categories/Widgets/widgets: - # Widget name type: profile # Where should the widget be placed, left or right position: left # Author name to be shown in the profile widget author: LotteWong # Title of the author to be shown in the profile widget author_title: SCUT, Undergraduate # Author's current location to be shown in the profile widget location: Guangzhou, China # Path or URL to the avatar to be shown in the profile widget avatar: # Email address for the Gravatar to be shown in the profile widget gravatar: # Whether to show avatar image rounded or square avatar_rounded: false # Path or URL for the follow button follow_link: 'https://www.jianshu.com/u/80ee6b6f3418' # Links to be shown on the bottom of the profile widget social_links: Project: icon: fab fa-creative-commons url: 'https://github.com/scutse-man-month-myth/InkYear' Organization: icon: fab fa-creative-commons-by url: 'https://github.com/scutse-man-month-myth' Developer: icon: fab fa-github url: 'https://github.com/LotteWong' #Facebook: #icon: fab fa-facebook #url: 'https://facebook.com' #Twitter: #icon: fab fa-twitter #url: 'https://twitter.com' #Dribbble: #icon: fab fa-dribbble #url: 'https://dribbble.com' - # Widget name type: toc # Where should the widget be placed, left or right position: left - # Widget name type: links # Where should the widget be placed, left or right position: left # Links to be shown in the links widget links: Dart: 'https://dart.dev/' Flutter: 'https://flutter.dev/' - # Widget name type: category # Where should the widget be placed, left or right position: left - # Widget name type: tagcloud # Where should the widget be placed, left or right position: left - # Widget name type: recent_posts # Where should the widget be placed, left or right position: right - # Widget name type: archive # Where should the widget be placed, left or right position: right - # Widget name type: tag # Where should the widget be placed, left or right position: right# Other plugin settingsplugins: # Enable page animations animejs: true # Enable the lightGallery and Justified Gallery plugins # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/gallery-plugin/ gallery: true # Enable the Outdated Browser plugin # http://outdatedbrowser.com/ outdated-browser: true # Enable the MathJax plugin # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/mathjax-plugin/ mathjax: true # Show the back to top button on mobile devices back-to-top: true # Google Analytics plugin settings # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Google-Analytics google-analytics: # Google Analytics tracking id tracking_id: # Baidu Analytics plugin settings # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Baidu-Analytics baidu-analytics: # Baidu Analytics tracking id tracking_id: # Hotjar user feedback plugin # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/site-analytics-plugin/#Hotjar hotjar: # Hotjar site id site_id: # Show a loading progress bar at top of the page progressbar: true # Show the copy button in the highlighted code area clipboard: true # BuSuanZi site/page view counter # https://busuanzi.ibruce.info busuanzi: false# CDN provider settings# https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/speed-up-your-site-with-custom-cdn/providers: # Name or URL of the JavaScript and/or stylesheet CDN provider cdn: jsdelivr # Name or URL of the webfont CDN provider fontcdn: google # Name or URL of the webfont Icon CDN provider iconcdn: fontawesome 博客写作 Writing 默认 1$ hexo new \"blog title\" 自定义 1234567891011title: {{ blog title }}categories: {{ blog category }}tags:- {{ blog tag }}thumbnail: {{ blog thumbnail }}{{ Abstract }}&lt;!-- more --&gt;{{ Content }} 双备份 Backup Hexo备份: 12# master branch$ hexo d Src备份: 12345# dev branch$ git checkout dev$ git add --all$ git commit -m \"new blog\"$ git push origin dev 待办事项 Todos 对应图标 更多插件 绑定域名 更新外链 参考链接 References GitHub+Hexo 搭建个人网站详细教程 Hexo icarus","link":"/2019/06/02/从零到壹：GitHub Pages + Hexo = Blog/"}],"tags":[{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"Concurrency","slug":"Concurrency","link":"/tags/Concurrency/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"WSL","slug":"WSL","link":"/tags/WSL/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"},{"name":"Fiddler","slug":"Fiddler","link":"/tags/Fiddler/"},{"name":"Programming Paradigm","slug":"Programming-Paradigm","link":"/tags/Programming-Paradigm/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"GitHub Pages","slug":"GitHub-Pages","link":"/tags/GitHub-Pages/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"}],"categories":[{"name":"Programming Language","slug":"Programming-Language","link":"/categories/Programming-Language/"},{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","link":"/categories/Artificial-Intelligence/"},{"name":"DevOps","slug":"DevOps","link":"/categories/DevOps/"},{"name":"Quick Ref Guide","slug":"Quick-Ref-Guide","link":"/categories/Quick-Ref-Guide/"},{"name":"Sucks","slug":"Sucks","link":"/categories/Sucks/"},{"name":"Testing","slug":"Testing","link":"/categories/Testing/"},{"name":"Cloud Computing","slug":"Cloud-Computing","link":"/categories/Cloud-Computing/"},{"name":"Others","slug":"Others","link":"/categories/Others/"}]}